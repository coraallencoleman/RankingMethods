#check data, create tables
#wide to long
#test %>%
program_yearly <- mutate(program_yearly, numWomenRatio = numWomen/(numWomen+numMen))
program_yearly <- mutate(program_yearly, withWomenRate = withWomen/(withWomen+withMen))
program_yearly <- mutate(program_yearly, matWomenRate = matWomen/(matWomen+matMen))
program_yearly <- mutate(program_yearly, gradWomenRate = gradWomen/(gradWomen+gradMen))
is.nan.data.frame <- function(x)
do.call(cbind, lapply(x, is.nan))
program_yearly[is.nan(program_yearly)] <- 0
sum(program_yearly$withMen)
sum(program_yearly$withWomen)
## Analysis ##
#averages summary
summary_table <- summarize(program_yearly, mean(numWomenRatio),mean(withWomenRate),
mean(matWomenRate), mean(gradWomenRate), WomenWithRate = withWomen/numWomen)
source('~/git_repos/seminarAnalysis/program_analysis.R', echo=TRUE)
#Longitudinal Analysis
require(tidyverse)
## Data Cleaning ##
program_data <- read.csv("/Users/cora/git_repos/seminarAnalysis/program_data.csv", stringsAsFactors = FALSE)
program_yearly <- program_data[2:22, c(1, 2, 3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17)]
colnames(program_yearly) <- c("year", "numWomen", "numMen", "matWomen", "matMen", "gradWomen",
"gradMen", "withWomen", "withMen", "sympStudWomen", "sympStudMen",
"sympKeyWomen", "sympKeyMen", "sympFacWomen", "sympFacMen")
program_yearly[,-1] <- mutate_all(program_yearly[,-1], function(x) as.numeric(x))
program_yearly$year <- as.numeric(substring(program_yearly$year,1,4))
program_yearly <- mutate(program_yearly, numWomenRatio = numWomen/(numWomen+numMen))
program_yearly <- mutate(program_yearly, matWomenRate = matWomen/(matWomen+matMen))
program_yearly <- mutate(program_yearly, gradWomenRate = gradWomen/(gradWomen+gradMen))
program_yearly <- mutate(program_yearly, WomenWithRate = withWomen/numWomen)
program_yearly <- mutate(program_yearly, MenWithRate = withWomen/numWomen)
is.nan.data.frame <- function(x)
do.call(cbind, lapply(x, is.nan))
program_yearly[is.nan(program_yearly)] <- 0
program_yearly <- mutate(program_yearly, WomenWithRate = withWomen/numWomen)
program_yearly <- mutate(program_yearly, MenWithRate = withMen/numMen)
## Analysis ##
#averages summary
summary_table <- summarize(program_yearly, mean(numWomenRatio),mean(withWomenRate),
mean(matWomenRate), mean(gradWomenRate), mean(WomenWithRate), mean(WomenWithRate))
## Analysis ##
#averages summary
summary_table <- summarize(program_yearly, mean(numWomenRatio),mean(matWomenRate),
mean(gradWomenRate), mean(WomenWithRate), mean(WomenWithRate))
View(summary_table)
## Analysis ##
#averages summary
summary_table <- summarize(program_yearly, mean(numWomenRatio),mean(matWomenRate),
mean(gradWomenRate), mean(WomenWithRate), mean(MenWithRate))
#female withdrawal rate by year
numPlot <- ggplot(program_yearly, aes(x = year, y = numWomenRatio)) +
geom_point(color = "black") + geom_line(color = "black") + ggtitle("Percent Program Women"); numPlot
#female withdrawal rate by year
numPlot <- ggplot(program_yearly, aes(x = year, y = numWomenRatio)) +
geom_point(color = "black") + geom_line(color = "black") + ggtitle("Percent Program Women")+
y_axis(c(0, 0)); numPlot
#female withdrawal rate by year
numPlot <- ggplot(program_yearly, aes(x = year, y = numWomenRatio)) +
geom_point(color = "black") + geom_line(color = "black") + ggtitle("Percent Program Women")+
y_lim(c(0, 0)); numPlot
#female withdrawal rate by year
numPlot <- ggplot(program_yearly, aes(x = year, y = numWomenRatio)) +
geom_point(color = "black") + geom_line(color = "black") + ggtitle("Percent Program Women")+
y_lim(0, 1); numPlot
#female withdrawal rate by year
numPlot <- ggplot(program_yearly, aes(x = year, y = numWomenRatio)) +
geom_point(color = "black") + geom_line(color = "black") + ggtitle("Percent Program Women")+
ylim(0, 1); numPlot
withPlot <- ggplot(program_yearly, aes(x = year, y = withWomenRate)) +
geom_point(color = "red") + geom_line(color = "red") + ggtitle("Percent Withdrawals Women"); withPlot
withPlot <- ggplot(program_yearly, aes(x = year, y = WomenWithRate)) +
geom_point(color = "red") + geom_line(color = "red") + ggtitle("Percent Withdrawals Women"); withPlot
matPlot <- ggplot(program_yearly, aes(x = year, y = matWomenRate)) +
geom_point(color = "black") + geom_line(color = "black") + ggtitle("Percent Matriculations Women");matPlot
matPlot <- ggplot(program_yearly, aes(x = year, y = matWomenRate)) +
geom_point(color = "black") + geom_line(color = "black") + ggtitle("Percent Matriculations Women") +
ylim(0, 1);matPlot
gradPlot <- ggplot(program_yearly, aes(x = year, y = gradWomenRate)) +
geom_point(color = "blue") + geom_line(color = "blue") + ggtitle("Percent Graduations Women"); gradPlot
gradPlot <- ggplot(program_yearly, aes(x = year, y = gradWomenRate)) +
geom_point(color = "blue") + geom_line(color = "blue") + ggtitle("Percent Graduations Women") +
ylim(0, 1); gradPlot
## Analysis ##
#averages summary
summary_table <- summarize(program_yearly, mean(numWomenRatio),mean(matWomenRate),
mean(gradWomenRate), mean(WomenWithRate), mean(MenWithRate))
#female withdrawal rate by year
numPlot <- ggplot(program_yearly, aes(x = year, y = numWomenRatio)) +
geom_point(color = "black") + geom_line(color = "black") + ggtitle("Percent Program Women")+
ylim(0, 1); numPlot
withPlot <- ggplot(program_yearly, aes(x = year, y = WomenWithRate)) +
geom_point(color = "red") + geom_line(color = "red") + ggtitle("Percent Withdrawals Women"); withPlot
matPlot <- ggplot(program_yearly, aes(x = year, y = matWomenRate)) +
geom_point(color = "black") + geom_line(color = "black") + ggtitle("Percent Matriculations Women") +
ylim(0, 1);matPlot
gradPlot <- ggplot(program_yearly, aes(x = year, y = gradWomenRate)) +
geom_point(color = "blue") + geom_line(color = "blue") + ggtitle("Percent Graduations Women") +
ylim(0, 1); gradPlot
### Weighted Loss Function for Ranking by Position ###
## Cora Allen-Coleman Spring 2018 ##
# Includes:
# Weighted Loss Ranking Function
# Weight Creation Function
library(rstan)
library(clue)
### Ranking Function for Extracting Parameters and Ranking ###
WeightedLossRanking <- function(model = NULL, sampleMatrix = NULL, parameter = NULL, loss = 2,  f=identity,
rankWeights = rep(1, times = n), itemweights = rep(1, times = n), lossTotal = FALSE){
# Computes optimal ranking for a list of estimates
#
# Args:
#   model: a stan model for the estimates
#   sampleMatrix: a matrix of samples. dim = n samples by n items. Result of PostSamples function
#   parameter: parameter to rank, as a string. Only necessary if inputting model rather than sampleMatrix.
#   loss: an exponent indicating the loss function for ranking. options: 2=square, 1=absolute, 0=zero
#   f: scale for loss calculation. options: identity, rank
#   rankWeights: a vector of length equal to number of items to be ranked. Weights positions.
#   itemweights: a vector of length equal to number of items to be ranked. Weights items.
#   lossTotal: if TRUE, provides total loss
#
# Returns:
#   optimal ranking for a list of estimates
# Dependencies: rstan, clue
if (!is.null(sampleMatrix)){ #checks for sampleMatrix
i = sampleMatrix
#print(dim(i)) #TODO remove
} else if (!is.null(model)){ #checks for model
print("model check") #TODO remove
i <- rstan::extract(model, pars=parameter)[[1]] #extract samples from model
}
rho_i <- apply(i, 1, f) #apply function/scale transformation to matrix i. Should this be on cols (2)?
rho_j <- apply(rho_i, 2, sort) #sort transformed samples (matrix j) so each column is sorted
n <- ncol(i) #n = # items to be ranked
if (loss == 0){
#Q: this doesn't make sense unless we're on the rank scale, right?
#TODO give an error if user tries to use another scale
LossRnk <- matrix(NA,n,n)
for (i in 1:n) {
for (j in 1:n) {
LossRnk[i,j] <- rankWeights[j]*itemweights[i]*mean(m_rho_i[i,]!=m_rho_j[j,])
}
}
if (lossTotal == TRUE){
print(paste("Total Loss: ", sum(LossRnk)))
}
return(solve_LSAP(LossRnk))
} else{ #all other loss cases
LossRnk <- matrix(NA,n,n)
for (i in 1:n) {
for (j in 1:n) {
LossRnk[i,j] <- rankWeights[j]*itemweights[i]*mean(abs((rho_i[i,]-rho_j[j,]))^loss)
}
}
if (lossTotal == TRUE){
print(paste("Total Loss: ", sum(LossRnk)))
}
return(solve_LSAP(LossRnk))
}
}
RankingWeights <- function(numItems = 20, priority = "top", steepness = .9){
# Computes optimal ranking for a list of estimates. Largest weight is always 1.
#
# Args:
#   numItems: number of items to rank
#   priority: focus for ranking. "even" to evenly weight, "top" to prioritize top ranked items, "bottom" for bottom ranked items, "both" for both.
#   steepness: size of e between 0 and 1. Smaller e creates steeper weights. Larger e creates more even weights. Planning to test 3 (slow, steady, steep)
#
# Returns:
#   vector of weights
weights <- vector(length = numItems)
items <- seq(1:numItems)
if (priority == "even"){
weights = rep(1, times = numItems)
} else if (priority == "top"){
weights = steepness^(items-1)
} else if (priority == "bottom"){
# reverse version (you care about last items only)
weights = steepness^((numItems-items))
} else if (priority == "both"){
# weights = c(1, e, e^2, ..., e^(n+1/2) middle, ..., e^2, e, 1)
#for even, repeats same weight at bottom. (if numItems = 20, items 10 and 11 will both have the smallest weight)
#for odd, one item will have smallest weight. (if numItems = 21, item 11 will have the smallest weight)
weights = steepness^(items-1) #top
weights[(round(numItems/2 + 0.1) + 1):numItems] = steepness^(items[(round(numItems/2)):0]-1) #bottom/second half
} else {
return("Priority must be given as 'even', 'top', 'bottom', or 'both'.")
}
return(weights)
}
#RankingWeights(numItems = 21, priority = "both") #11 should be middle/lowest
#Step 0: Load
library(rstan)
library(dplyr)
library(rstanarm)
#AND run ranking_function.r, ranking_metric.r files.
set.seed(10)
SelectNP <- function(N = 25, a_p = 1, b_p = 1, n_min = 10, n_max = 30, a_n = 1, b_n = 1,
n_assignment_method = "ascending"){
# function to simulate n, p from parameters. Deterministic.
#
# Args:
#   N: number of items to rank
#   a_p: Shape parameter alpha for beta distribution to determine gaps in p. Allows for equal or nonequal gap size.
#   b_p: Shape parameter beta for beta distribution to determine gaps in p. Allows for equal or nonequal gap size.
#   n_min: minimum number of counts/tries for each binomial variable
#   n_max: maximum number of counts/tries for each binomial variable
#   a_n: Shape parameter alpha for beta distribution to determine gaps in n. Allows for equal or nonequal gap size.
#   b_n: Shape parameter alpha for beta distribution to determine gaps in n. Allows for equal or nonequal gap size.
#   n_assignment_method. Possibilities: "ascending" for assign in order, "descending" for assign in reverse order,
#   "random" for random assignment
#
# Returns:
#   one matrix with 2 columns (n, p) and N rows
#
# Dependencies:
output <- matrix(data = NA, nrow = N, ncol = 3,
dimnames = list(seq(1:N), c("item", "n", "p"))) #rows 1 to N, columns n, p
#item (county, etc)
output[,1] <- seq(1:N)
#n
output[,2] <- round(n_min + (n_max-n_min)*qbeta(1:N/(N+1), a_n, b_n), digits=0) #quantiles
#p
output[,3] <- qbeta((1:N)/(N+1), a_p, b_p)
return(output)
}
SimData <- function(matrix){
#simulates data from a dataframe of n, p
# Args:
#   matrix of deterministic n, p: A list of matrices containing N rows and 2 columns (n, p). Result of SelectNP where:
#     n is the true attempts/tries/counts
#     p is the true p
#
# Returns:
#   matrix of N rows and 2 columns (n, y) where n is attempts and y is successes
#   alternative formulation (not used here): matrix of N rows and n_sim columns and make ONE deterministic n vector
#
# Dependencies:
N <- length(matrix[,1]) #number of items to rank (from SelectNP matrix)
output <- matrix(data = NA, nrow = N, ncol = 3,
dimnames = list(seq(1:N), c("item","n", "y")))
#item
output[,1] <- seq(1:N)
#n (These are deterministic.)
output[,2] <- matrix[,2] #
#y counts (These vary randomly.)
output[,3] <- rbinom(N, size = matrix[,2], prob = matrix[,3])
return(output)
}
#Get Posterior Samples
PostSamples <- function(data){
#simulates data from a dataframe of n, p
# Args:
#   list of dataframes. Each dataframe has 3 columns named: item, n, p. Output of SimData
#
# Returns:
#   one matrix of posterior samples. The matrix has one row for each iteration, one column for each item parameter estimated
#
# Dependencies: rstanarm
library(rstanarm)
options(mc.cores = parallel::detectCores())
model1 <- stan_glmer(cbind(y, n - y) ~ (1|item), data = as.data.frame(data),
family = binomial(link=logit), prior_intercept = normal(0, 5),
prior_aux = cauchy(0,1),
seed = 12345)
output <- as.matrix(model1, regex_pars = "b[(Intercept) item:[0-9]+]")
return(output)
}
## RUN EXPERIMENT
RunSimulation <- function(N = 10, a_p = 1, b_p = 1, n_min = 10, n_max = 30, a_n = 1, b_n = 1, #data
n_assignment_method = "ascending",
rankPriority = "top", rankSteepness = .9, #rankWeights
parameter = NULL, loss = 2, f=identity, rankweights = "", #ranking settings
n_sim = 1,
fileRoot = "/Users/cora/git_repos/RankingMethods/results/",
metric = FALSE, metricFile = "/Users/cora/git_repos/RankingMethods/results/metricResults.csv"){
#combines all the above functions to run a simulation
# Args:
#   for SelectNP:
#   N: number of items to rank
#   a_p: Shape parameter alpha for beta distribution to determine gaps in p. Allows for equal or nonequal gap size.
#   b_p: Shape parameter beta for beta distribution to determine gaps in p. Allows for equal or nonequal gap size.
#   n_min: minimum number of counts/tries for each binomial variable
#   n_max: maximum number of counts/tries for each binomial variable
#   a_n: Shape parameter alpha for beta distribution to determine gaps in n. Allows for equal or nonequal gap size.
#   b_n: Shape parameter alpha for beta distribution to determine gaps in n. Allows for equal or nonequal gap size.
#   n_assignment_method. Possibilities: "ascending" for assign in order, "descending" for assign in reverse order,
#   "random" for random assignment
#   list of dataframes. Each dataframe has 3 columns named: item, n, p. Output of SimData
#   loss: an exponent indicating the loss function for ranking. options: 2=square, 1=absolute, 0=zero
#   f = scale on which to rank
#   rankweights: a vector of weights for ranks. Can be result of RankingWeights
#   n_sim: number of simulations. (reps)
#   fileRoot: file path used to create csv file for results
#   metric: boolean indicating if metric results should be created and saved
#   metricFile: csv file for metric results
#
# Returns:
#   list of matrices of posterior samples, one column for each item
# Saves: csv of ranks (n_sim columns)
#
# Dependencies: rstanarm
settings <- SelectNP(N, a_p, b_p, n_min, n_max, a_n, b_n, n_assignment_method) #this happens once per experiment
# create RankingWeights
rankWeights <- RankingWeights(numItems = N, priority = rankPriority, steepness = rankSteepness)
ranks <- list() #creates list of ranks for each simulation
results <- list() #create list of metric results for each simulation
for (i in 1:n_sim){
data <- SimData(settings)
post <- PostSamples(data)
ranks[[i]] <- as.integer(WeightedLossRanking(sampleMatrix = post, parameter = NULL, loss = loss, f=f,
rankWeights = rankWeights, lossTotal = FALSE))
if (metric == TRUE){
results[[i]] <- RankMetric(ranks, settings = data)
}
}
#create rank file containing all info needed for experiment
#TODO need to include function like identity or rank here. Could use as.character(quote(f)). For now, just assumes identity
rankFile = paste(fileRoot, N, a_p, b_p, n_min, n_max, a_n, b_n, n_assignment_method,rankPriority,
rankSteepness, parameter, loss, "identity", rankPriority, rankSteepness, n_sim, ".csv", sep = "_")
#save ranks to a file (one column for each sim)
write.csv(ranks, file = rankFile)
#save metric results to a file
if (metric == TRUE){
write.csv(results, file = metricFile)
}
return(ranks)
}
#test
ranks <- RunSimulation(n_sim = 1)
se = sqrt((.1*.9)/20)
se
## RUN EXPERIMENT
RunSimulation <- function(N = 10, a_p = 1, b_p = 1, n_min = 10, n_max = 30, a_n = 1, b_n = 1, #data
n_assignment_method = "ascending",
rankPriority = "top", rankSteepness = .9, #rankWeights
parameter = NULL, loss = 2, f=identity, #ranking settings
n_sim = 1,
fileRoot = "/Users/cora/git_repos/RankingMethods/results/",
metric = FALSE, metricFile = "/Users/cora/git_repos/RankingMethods/results/metricResults.csv"){
#combines all the above functions to run a simulation
# Args:
#   for SelectNP:
#   N: number of items to rank
#   a_p: Shape parameter alpha for beta distribution to determine gaps in p. Allows for equal or nonequal gap size.
#   b_p: Shape parameter beta for beta distribution to determine gaps in p. Allows for equal or nonequal gap size.
#   n_min: minimum number of counts/tries for each binomial variable
#   n_max: maximum number of counts/tries for each binomial variable
#   a_n: Shape parameter alpha for beta distribution to determine gaps in n. Allows for equal or nonequal gap size.
#   b_n: Shape parameter alpha for beta distribution to determine gaps in n. Allows for equal or nonequal gap size.
#   n_assignment_method. Possibilities: "ascending" for assign in order, "descending" for assign in reverse order,
#     "random" for random assignment
#   list of dataframes. Each dataframe has 3 columns named: item, n, p. Output of SimData
#   loss: an exponent indicating the loss function for ranking. options: 2=square, 1=absolute, 0=zero
#   f = scale on which to rank
#   n_sim: number of simulations. (reps)
#   fileRoot: file path used to create csv file for results
#   metric: boolean indicating if metric results should be created and saved
#   metricFile: csv file for metric results
#
# Returns:
#   list of matrices of posterior samples, one column for each item
# Saves: csv of ranks (n_sim columns)
#
# Dependencies: rstanarm
settings <- SelectNP(N, a_p, b_p, n_min, n_max, a_n, b_n, n_assignment_method) #this happens once per experiment
# create RankingWeights
rankWeights <- RankingWeights(numItems = N, priority = rankPriority, steepness = rankSteepness)
ranks <- list() #creates list of ranks for each simulation
results <- list() #create list of metric results for each simulation
for (i in 1:n_sim){
data <- SimData(settings)
post <- PostSamples(data)
ranks[[i]] <- as.integer(WeightedLossRanking(sampleMatrix = post, parameter = NULL, loss = loss, f=f,
rankWeights = rankWeights, lossTotal = FALSE))
if (metric == TRUE){
results[[i]] <- RankMetric(ranks, settings = data)
}
}
#create rank file containing all info needed for experiment
#TODO need to include function like identity or rank here. Could use as.character(quote(f)). For now, just assumes identity
rankFile = paste(fileRoot, N, a_p, b_p, n_min, n_max, a_n, b_n, n_assignment_method,rankPriority,
rankSteepness, parameter, loss, "identity", rankPriority, rankSteepness, n_sim, ".csv", sep = "_")
#save ranks to a file (one column for each sim)
write.csv(ranks, file = rankFile)
#save metric results to a file
if (metric == TRUE){
write.csv(results, file = metricFile)
}
return(ranks)
}
for (n in c(25, 50, 100)){ #numItems
for (n_min in c(10, 50, 100)){
for (n_max in c(30, 100, 200)){
#for (l in c(1, 2)){ #loss types
RunSimulation(N = n, a_p = 1, b_p = 1, n_min = 20, n_max = 30, a_n = 1, b_n = 1, #data
n_assignment_method = "ascending",
rankPriority = "even", #rankSteepness = .9, #rankWeights
parameter = NULL, loss = 2,
f=identity,  #ranking settings
n_sim = 1,
fileRoot = "/Users/cora/git_repos/RankingMethods/results/",
metric = FALSE)
}
}
}
#for (n in c(25, 50, 100)){ #numItems
for (n_min in c(10, 50, 100)){
for (n_max in c(30, 100, 200)){
#for (l in c(1, 2)){ #loss types
RunSimulation(N = n, a_p = 1, b_p = 1, n_min = n_min, n_max = n_max, a_n = 1, b_n = 1, #data
n_assignment_method = "ascending",
rankPriority = "even", #rankSteepness = .9, #rankWeights
parameter = NULL, loss = 2,
f=identity,  #ranking settings
n_sim = 1,
fileRoot = "/Users/cora/git_repos/RankingMethods/results/",
metric = FALSE)
}
}
setwd("/Users/cora/git_repos/RankingMethods/results")
n100_200 <- read.csv(file = "_100_1_1_100_200_1_1_ascending_even_0.9__2_identity_even_0.9_1_.csv")
head(n100_200)
## RUN EXPERIMENT
RunSimulation <- function(N = 10, a_p = 1, b_p = 1, n_min = 10, n_max = 30, a_n = 1, b_n = 1, #data
n_assignment_method = "ascending",
rankPriority = "top", rankSteepness = .9, #rankWeights
parameter = NULL, loss = 2, f=identity, #ranking settings
n_sim = 1, lossTotal = FALSE,
fileRoot = "/Users/cora/git_repos/RankingMethods/results/",
metric = FALSE, metricFile = "/Users/cora/git_repos/RankingMethods/results/metricResults.csv"){
#combines all the above functions to run a simulation
# Args:
#   for SelectNP:
#   N: number of items to rank
#   a_p: Shape parameter alpha for beta distribution to determine gaps in p. Allows for equal or nonequal gap size.
#   b_p: Shape parameter beta for beta distribution to determine gaps in p. Allows for equal or nonequal gap size.
#   n_min: minimum number of counts/tries for each binomial variable
#   n_max: maximum number of counts/tries for each binomial variable
#   a_n: Shape parameter alpha for beta distribution to determine gaps in n. Allows for equal or nonequal gap size.
#   b_n: Shape parameter alpha for beta distribution to determine gaps in n. Allows for equal or nonequal gap size.
#   n_assignment_method. Possibilities: "ascending" for assign in order, "descending" for assign in reverse order,
#     "random" for random assignment
#   list of dataframes. Each dataframe has 3 columns named: item, n, p. Output of SimData
#   loss: an exponent indicating the loss function for ranking. options: 2=square, 1=absolute, 0=zero
#   f = scale on which to rank
#   n_sim: number of simulations. (reps)
#   fileRoot: file path used to create csv file for results
#   metric: boolean indicating if metric results should be created and saved
#   metricFile: csv file for metric results
#
# Returns:
#   list of matrices of posterior samples, one column for each item
# Saves: csv of ranks (n_sim columns)
#
# Dependencies: rstanarm
settings <- SelectNP(N, a_p, b_p, n_min, n_max, a_n, b_n, n_assignment_method) #this happens once per experiment
# create RankingWeights
rankWeights <- RankingWeights(numItems = N, priority = rankPriority, steepness = rankSteepness)
ranks <- list() #creates list of ranks for each simulation
results <- list() #create list of metric results for each simulation
for (i in 1:n_sim){
data <- SimData(settings)
post <- PostSamples(data)
ranks[[i]] <- as.integer(WeightedLossRanking(sampleMatrix = post, parameter = NULL, loss = loss, f=f,
rankWeights = rankWeights, lossTotal = lossTotal))
if (metric == TRUE){
results[[i]] <- RankMetric(ranks, settings = data)
}
}
#create rank file containing all info needed for experiment
#TODO need to include function like identity or rank here. Could use as.character(quote(f)). For now, just assumes identity
rankFile = paste(fileRoot, N, a_p, b_p, n_min, n_max, a_n, b_n, n_assignment_method,rankPriority,
rankSteepness, parameter, loss, "identity", rankPriority, rankSteepness, n_sim, ".csv", sep = "_")
#save ranks to a file (one column for each sim)
write.csv(ranks, file = rankFile)
#save metric results to a file
if (metric == TRUE){
write.csv(results, file = metricFile)
}
return(ranks)
}
c(c(10, 30))
c(c(10, 30), c(10, 100))
#for (n in c(25, 50, 100)){ #numItems
for (n_min in c(10, 50, 100)){
for (n_max in c(30, 100, 200)){
#for (l in c(1, 2)){ #loss types
RunSimulation(N = n, a_p = 1, b_p = 1, n_min = n_min, n_max = n_max, a_n = 1, b_n = 1, #data
n_assignment_method = "ascending",
rankPriority = "even", #rankSteepness = .9, #rankWeights
parameter = NULL, loss = 2,
f=identity,  #ranking settings
n_sim = 1, lossTotal = TRUE,
fileRoot = "/Users/cora/git_repos/RankingMethods/results/",
metric = FALSE)
}
}
#for (n in c(25, 50, 100)){ #numItems
for (n_min in c(10, 50, 100)){
#for (n_max in c(30, 100, 200)){
#for (l in c(1, 2)){ #loss types
RunSimulation(N = n, a_p = 1, b_p = 1, n_min = n_min, n_max = 200, a_n = 1, b_n = 1, #data
n_assignment_method = "ascending",
rankPriority = "even", #rankSteepness = .9, #rankWeights
parameter = NULL, loss = 2,
f=identity,  #ranking settings
n_sim = 1, lossTotal = TRUE,
fileRoot = "/Users/cora/git_repos/RankingMethods/results/",
metric = FALSE)
#}
}
