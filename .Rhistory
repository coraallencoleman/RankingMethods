return("Priority must be given as 'even', 'top', 'bottom', or 'both'.")
}
return(weights)
}
SelectNP <- function(N = 25, a_p = 1, b_p = 1, n_min = 10, n_max = 30, a_n = 1, b_n = 1,
n_assignment_method = "ascending"){
# function to simulate n, p from parameters. Deterministic.
#
# Args:
#   N: number of items to rank
#   a_p: Shape parameter alpha for beta distribution to determine gaps in p. Allows for equal or nonequal gap size.
#   b_p: Shape parameter beta for beta distribution to determine gaps in p. Allows for equal or nonequal gap size.
#   n_min: minimum number of counts/tries for each binomial variable
#   n_max: maximum number of counts/tries for each binomial variable
#   a_n: Shape parameter alpha for beta distribution to determine gaps in n. Allows for equal or nonequal gap size.
#   b_n: Shape parameter alpha for beta distribution to determine gaps in n. Allows for equal or nonequal gap size.
#   n_assignment_method. Possibilities: "ascending" for assign in order, "descending" for assign in reverse order,
#   "random" for random assignment
#
# Returns:
#   one matrix with 2 columns (n, p) and N rows
#
# Dependencies:
output <- matrix(data = NA, nrow = N, ncol = 3,
dimnames = list(seq(1:N), c("item", "n", "p"))) #rows 1 to N, columns n, p
#item (county, etc)
output[,1] <- seq(1:N)
#n
n_vec <- round(n_min + (n_max-n_min)*qbeta(1:N/(N+1), a_n, b_n), digits=0) #quantiles
if (n_assignment_method == "ascending"){
output[,2] <- n_vec
} else if (n_assignment_method == "descending"){
output[,2] <- rev(n_vec)
} else if (n_assignment_method == "random"){
output[,2] <- sample(n_vec)
} else{
return("n_assignment_method must equal ascending, descending or random.")
}
#p
output[,3] <- qbeta((1:N)/(N+1), a_p, b_p)
return(output)
}
SimData <- function(matrix){
#simulates data from a dataframe of n, p
# Args:
#   matrix of deterministic n, p: A list of matrices containing N rows and 2 columns (n, p). Result of SelectNP where:
#     n is the true attempts/tries/counts
#     p is the true p
#
# Returns:
#   matrix of N rows and 2 columns (n, y) where n is attempts and y is successes
#   alternative formulation (not used here): matrix of N rows and n_sim columns and make ONE deterministic n vector
#
# Dependencies:
N <- length(matrix[,1]) #number of items to rank (from SelectNP matrix)
output <- matrix(data = NA, nrow = N, ncol = 3,
dimnames = list(seq(1:N), c("item","n", "y")))
#item
output[,1] <- seq(1:N)
#n (These are deterministic.)
output[,2] <- matrix[,2] #
#y counts (These vary randomly.)
output[,3] <- rbinom(N, size = matrix[,2], prob = matrix[,3]) #TODO check this matrix[,3]
return(output)
}
PostSamples <- function(data){
#gets posterior samples from data using a dataframe of n, p
# Args:
#   matrix of N rows and 2 columns (n, y) where n is attempts and y is successes. Output of SimData
#
# Returns:
#   one matrix of posterior samples. The matrix has one row for each iteration, one column for each item parameter estimated
#
# Dependencies: rstanarm
library(rstanarm)
options(mc.cores = parallel::detectCores())
model1 <- stan_glmer(cbind(y, n - y) ~ (1|item), data = as.data.frame(data), iter = 3000, #default iter = 2000
family = binomial(link=logit), prior_intercept = normal(0, 5),
prior_aux = cauchy(0,1),
seed = 12345)
output <- as.matrix(model1, regex_pars = "b[(Intercept) item:[0-9]+]")
return(output)
}
PostSamplesEB <- function(data){
#gets posterior samples from data using a dataframe of n, p using empirical bayes. Should be more efficient
# Args:
#   matrix of N rows and 2 columns (n, y) where n is attempts and y is successes. Output of SimData
#
# Returns:
#   one matrix of posterior samples. The matrix has one row for each iteration, one column for each item parameter estimated
#
# Dependencies: lme4, mgcv
library(mgcv)
library(lme4)
model1 <- glmer(cbind(y, n - y) ~ (1|item), data = as.data.frame(data),
family = binomial(link=logit))
coef <- fixef(model1)[1] + ranef(model1)$item #gives only random effects, need to add fix effects
#varcov of fixed and random effects
fix_var <- vcov(model1)[1]
vc <- matrix(nrow = nrow(coef), ncol = nrow(coef), 0)
ran_vars <- attr(ranef(model1, condVar=TRUE)[[1]], "postVar")
diag(vc) <- fix_var + ran_vars #bc var(sum) = sum(vars)
output <- rmvn(1000, coef$'(Intercept)', vc) #creates posterior
return(output)
}
RunSimulation <- function(N = 10, a_p = 1, b_p = 1, n_min = 10, n_max = 30, a_n = 1, b_n = 1, #data
n_assignment_method = "ascending",
rankPriority = "top", rankSteepness = .9, #rankWeights
parameter = NULL, loss = 2, f=identity, #ranking settings
n_sim = 1){
#combines all the above functions to run simulations
# Args:
#   for SelectNP:
#   N: number of items to rank
#   a_p: Shape parameter alpha for beta distribution to determine gaps in p. Allows for equal or nonequal gap size.
#   b_p: Shape parameter beta for beta distribution to determine gaps in p. Allows for equal or nonequal gap size.
#   n_min: minimum number of counts/tries for each binomial variable
#   n_max: maximum number of counts/tries for each binomial variable
#   a_n: Shape parameter alpha for beta distribution to determine gaps in n. Allows for equal or nonequal gap size.
#   b_n: Shape parameter alpha for beta distribution to determine gaps in n. Allows for equal or nonequal gap size.
#   n_assignment_method. Possibilities: "ascending" for assign in order, "descending" for assign in reverse order,
#     "random" for random assignment
#   rankPriority: can be a list
#   rankSteepness: can be a list
#   loss: an exponent indicating the loss function for ranking. options: 2=square, 1=absolute, 0=zero can be a list
#   f = scale on which to rank. can be a list
#   n_sim: number of simulations. (reps)
#
# Returns:
#   list of matrices of posterior samples, one column for each item
#   saves .RData of settings, totalLoss, and ranking
#
# Dependencies: rstanarm, clue
rankWeights <- as.data.frame(matrix(nrow = 0, ncol = 3))
names(rankWeights) <- c("rw", "rankPriority", "rankSteepness")
for (rp in rankPriority){
for (rs in rankSteepness){
rw <- list(as.double(RankingWeights(numItems = N, priority = rp, steepness = rs)))
rankWeights[nrow(rankWeights) + 1,] <- list(I(rw), rp, rs)
}
}
#push ps closer in debugging or make n small enough (keep making smaller)
# as we increase sample size, it'll become clearer
#TODO dont worry about random for now. The sample size being fixed is of interest. What happens when tail has lots of small samples,
#lots of big samples. Eventually, some scenarios where its mixed, but we'll mostly make this fixed later
settings <- SelectNP(N, a_p, b_p, n_min, n_max, a_n, b_n, n_assignment_method) #this happens once per experiment
for (i in 1:n_sim){   #for each simulation
data <- SimData(settings)
post <- PostSamplesEB(data)
for (l in loss){ #loss types square and absolute
#for (iden in f){
for (rp in rankPriority){
for (rs in rankSteepness){
ranks <- list()
rankFunctionResult <- WeightedLossRanking(sampleMatrix = post, parameter = parameter, loss = l, #f=iden,
rankWeights = filter(rankWeights, rankPriority == rp, rankSteepness == rs)$rw[[1]])
totalLoss <- as.numeric(sum(rankFunctionResult[[1]])) #this is an nxn rank matrix, so loss = sum(matrix)
ranks <- list(as.integer(rankFunctionResult[[2]]))
row <- c(i, N, a_p, b_p, n_min, n_max, a_n, b_n,
n_assignment_method,
rp, rs,"identity", l, totalLoss, "placeholder", "placeholder")
currResults[nrow(currResults) + 1, ] <- row
currResults$ranking[nrow(currResults)] <- ranks
currResults[[nrow(currResults), 16]] <- data ##save true data (SimData)
}
#  }
}
}
}
return(currResults)
}
# A testing metric for use with simulated data
##function metric to see if rankObject's top ranked items match true top items MATRIX
#TODO FIX this is created a list of 10 logicals NOT five or fifteen
RankMetric <- function(rankObject = NULL, order = "largest", topN = 5){
# function metric to see how much of our top N includes true top N
# note: correct order is always item number because SelectNP assigns true p in order
#
# Args:
#   rankObject: an output of WeightedLossRanking.
#   originalData: a data frame with column of item IDs, n, true probabilities
#   order: largest (largest to smallest) or smallest (smallest to largest)
#   topN: an integer number of top items to compare
#
# Returns:
#   logical vector
#
# Dependencies: rstan, clue, dplyr
ranking <- as.integer(rankObject[[1]][1:topN])
return(1:topN %in% ranking)
}
RankMetricStrict <- function(rankObject = NULL, order = "largest", topN = 5){
# function metric to see how much of top N is correctly ranked (order matters here)
# (more strict metric than RankMetric)
# note: correct order is always item number because SelectNP assigns true p in order
#
# Args:
#   rankObject: an output of WeightedLossRanking.
#   data: a data frame with column of item IDs, n, true probabilities TODO: do we actually need this? correct rank always 1:N
#   order: largest (largest to smallest) or smallest (smallest to largest)
#   topN: an integer number of top items to compare
#
# Returns:
#   logical
#
# Dependencies: rstan, clue, dplyr
ranking <- as.integer(rankObject[[1]][1:topN])
return(1:topN == ranking)
}
#Step 2: add weights
rankPriority = c("top", "bottom", "both")
rankSteepness = c(0, 0.0001, 0.001, 0.01,  0.1, 0.3, .5, .7, .9) #rankWeights
rankWeights <- as.data.frame(matrix(nrow = 0, ncol = 3))
names(rankWeights) <- c("rw", "rankPriority", "rankSteepness")
for (rp in rankPriority){
for (rs in rankSteepness){
rw <- list(as.double(RankingWeights(numItems = N, priority = rp, steepness = rs)))
rankWeights[nrow(rankWeights) + 1,] <- list(I(rw), rp, rs)
}
}
#Step 2: add weights
N = 71
rankPriority = c("top", "bottom", "both")
rankSteepness = c(0, 0.0001, 0.001, 0.01,  0.1, 0.3, .5, .7, .9) #rankWeights
rankWeights <- as.data.frame(matrix(nrow = 0, ncol = 3))
names(rankWeights) <- c("rw", "rankPriority", "rankSteepness")
for (rp in rankPriority){
for (rs in rankSteepness){
rw <- list(as.double(RankingWeights(numItems = N, priority = rp, steepness = rs)))
rankWeights[nrow(rankWeights) + 1,] <- list(I(rw), rp, rs)
}
}
rankWeights <- as.data.frame(matrix(nrow = 0, ncol = 3))
names(rankWeights) <- c("rw", "rankPriority", "rankSteepness")
for (rp in rankPriority){
for (rs in rankSteepness){
rw <- list(as.double(RankingWeights(numItems = N, priority = rp, steepness = rs)))
rankWeights[nrow(rankWeights) + 1,] <- list(I(rw), rp, rs)
}
}
#Step 2: add weights
N = 71
rankPriority = c("top", "bottom")
rankSteepness = c(0, 0.0001, 0.001, 0.01,  0.1, 0.3, .5, .7, .9) #rankWeights
rankWeights <- as.data.frame(matrix(nrow = 0, ncol = 3))
names(rankWeights) <- c("rw", "rankPriority", "rankSteepness")
for (rp in rankPriority){
for (rs in rankSteepness){
rw <- list(as.double(RankingWeights(numItems = N, priority = rp, steepness = rs)))
rankWeights[nrow(rankWeights) + 1,] <- list(I(rw), rp, rs)
}
}
rankWeights
#calculating loss on rank scale
SEL_rank <- matrix(NA,71,71) #square error loss
for (i in 1:71) {
for (j in 1:71) {
SEL_rank[i,j] <- rankWeights = filter(rankWeights, rankPriority == "top", rankSteepness ==9e-01)$rw[[1]]mean((lbw_ranks[i,]-j)^2)
}
}
#calculating loss on rank scale
SEL_rank <- matrix(NA,71,71) #square error loss
for (i in 1:71) {
for (j in 1:71) {
SEL_rank[i,j] <- rankWeights = filter(rankWeights, rankPriority == "top", rankSteepness ==9e-01)$rw[[1]]*mean((lbw_ranks[i,]-j)^2)
}
}
#calculating loss on rank scale
SEL_rank <- matrix(NA,71,71) #square error loss
for (i in 1:71) {
for (j in 1:71) {
SEL_rank[i,j] <- filter(rankWeights, rankPriority == "top", rankSteepness ==9e-01)$rw[[1]]*mean((lbw_ranks[i,]-j)^2)
}
}
filter(rankWeights, rankPriority == "top", rankSteepness ==9e-01)$rw[[1]]
#Step 3:
post <- PostSamplesEB(lbw_wi) #uses lbw_wi
View(lbw_wi)
#Step 3:
lbw_wi$y <- lbw_wi$lbw
lbw_wi$n <- lbw_wi$births
post <- PostSamplesEB(lbw_wi) #uses lbw_wi
#Step 3:
lbw_wi$y <- lbw_wi$lbw
lbw_wi$n <- lbw_wi$births
lbw_wi$item <- lbw_wi$county
post <- PostSamplesEB(lbw_wi) #uses lbw_wi
WeightedLossRanking(sampleMatrix = post, parameter = parameter, loss = 2, #f=iden,
rankWeights = filter(rankWeights, rankPriority == "top", rankSteepness ==9e-01)$rw[[1]])
#Step 4: Viz
#rename for viz
lbw_rank_SEL_rank_joint_opt <- as.numeric(solve_LSAP(SEL_rank)) #jointly optimal ranks
library(tidyverse)
library(reshape2)
library(coda)
library(clue)
setwd("/Users/cora/git_repos/RankingMethods/")
lbw_wi <- read_csv("lbw_wi.csv")
#remove missing, then create N normal birth weight, % LBW columns
lbw_wi <- lbw_wi %>% mutate(nbw=births-lbw,perc_lbw=lbw/births*100) %>% filter(!is.na(lbw))
#sample from LBW beta distribution using lbw as shape1, nbw as shape2 Q
lbw_samples <- replicate(10000,
rbeta(n = 71, shape1=lbw_wi$lbw, shape2=lbw_wi$nbw))
#if p follows beta(a,b) and y follows bin(n,p) then p|y follows beta(a+y, b+n-y)
#This is an improper prior (a,b cannot be 0), but this becomes a proper posterior
#as long as you have > 0 successes and > 0 failures. close to doing a bootstrap. like a null model.
lbw_ranks <- apply(lbw_samples,2,rank) #Q doesnt this flip? I use 1 here in WeightedLossRanking function
lbw_order <- apply(lbw_samples,2,sort)
#when you do things by rows (2), it doesn't flip. Always outputs same.
#creates 71 X 2 MATRIX of HPD intervals
lbw_HPD <- t(apply(lbw_samples,1,function(x) HPDinterval(mcmc(x))))
lbw_rank_HPD <- t(apply(lbw_ranks,1,function(x) HPDinterval(mcmc(x))))
lbw_order_HPD <- t(apply(lbw_order,1,function(x) HPDinterval(mcmc(x))))
#calculating loss on rank scale
SEL_rank <- matrix(NA,71,71) #square error loss
for (i in 1:71) {
for (j in 1:71) {
SEL_rank[i,j] <- mean((lbw_ranks[i,]-j)^2)
}
}
#calculating loss on prob scale?
SEL_prob <- matrix(NA,71,71)
for (i in 1:71) {
for (j in 1:71) {
SEL_prob[i,j] <- mean((lbw_samples[i,]-lbw_order[j,])^2)
}
}
lbw_rank_pm <- apply(lbw_ranks,1,mean) #posterior mean
lbw_rank_SEL_rank_ind_opt <- apply(SEL_rank,1,which.min) #individually optimal ranks
lbw_rank_SEL_rank_joint_opt <- as.numeric(solve_LSAP(SEL_rank)) #jointly optimal ranks
lbw_rank_SEL_prob_ind_opt <- apply(SEL_prob,1,which.min) #individually optimal ranks on pr scale
lbw_rank_SEL_prob_joint_opt <- as.numeric(solve_LSAP(SEL_prob)) #jointly optimal ranks on pr scale
#Q: to get comparison probabilities to compare. What's pr that pepin has sm rate than mil
#creates 71x71 matrix Pr(county i LBW % <county j LBW %) This is comparison-wise loss.
#a potential loss is pr of those comparisons you get right = sum(upper triangle).
#want to min(sum lower triangle). There isnt a clear algorithm that solves this.
#Diagonal should be .5 but its 0. this only matters if looking for min
prob1 <- matrix(NA,71,71)
for (i in 1:71) {
for (j in 1:71) {
prob1[i,j] <- mean(lbw_samples[i,]<lbw_samples[j,])
}
}
#prob1a <- prob1[order(rank2a),order(rank2a)]
## VISUALIZATIONS ##
#creates data frame for all the things we've calculated above for viz
lbw_results_selr <- data_frame(county=lbw_wi$county, #SEL rank scale DF
LBW_pm=apply(lbw_samples,1,mean),
LBW_LCL=lbw_HPD[,1],
LBW_UCL=lbw_HPD[,2],
LBW_rank_pm=lbw_rank_pm,
LBW_rank_io=lbw_rank_SEL_rank_ind_opt,
LBW_rank_jo=lbw_rank_SEL_rank_joint_opt,
LBW_rank_LCL=lbw_rank_HPD[,1],
LBW_rank_UCL=lbw_rank_HPD[,2]) %>%
arrange(LBW_rank_jo)
lbw_results_selp <- data_frame(county=lbw_wi$county, #pr scale DF
LBW_pm=apply(lbw_samples,1,mean),
LBW_LCL=lbw_HPD[,1],
LBW_UCL=lbw_HPD[,2],
LBW_rank_io=lbw_rank_SEL_prob_ind_opt,
LBW_rank_jo=lbw_rank_SEL_prob_joint_opt,
LBW_rank_LCL=lbw_rank_HPD[,1],
LBW_rank_UCL=lbw_rank_HPD[,2]) %>%
arrange(LBW_rank_jo)
#creates pr and scales them. Pr(given county at that rank relative to its posterior mode)
#gives realtive prob in rank direction but not relative to other counties
post_ranks <- t(apply(lbw_ranks,1,function(x) table(factor(x,levels=1:71))/max(table(factor(x,levels=1:71)))))
#post_ranks <- t(apply(lbw_ranks,1,function(x) table(factor(x,levels=1:71))/10000)) #real posterior probabilities. issue: greys out most places
#post_ranks <- post_ranks/max(post_ranks) #Q:
post_df <- melt(post_ranks) #makes it long because that's what gg plot needs
post_df$county <- lbw_wi$county[post_df$Var1]
post_df$rank <- post_df$Var2
post_df$pos <- lbw_order_stats[post_df$Var2] #TODO lbw_order_stats doesnt exist yet. needs to be created. post means of rows
post_df$county <- factor(post_df$county,levels=rev(lbw_wi$county[order(lbw_rank_SEL_prob_joint_opt)]),ordered=TRUE)
#puts them in correct order in visualization. Makes this an ordered factor. Reverse is because he wants low at top, high at bottom
#grey scale rank viz #Q
ggplot(post_df,aes(x=rank,y=county,color=value))+
geom_point(pch=15,cex=2)+
scale_y_discrete("") +
scale_x_continuous("",breaks=seq(1,71,by=5)) +
#  scale_x_continuous(breaks=lbw_order_stats[c(1:7,seq(10,60,by=10),67:71)],minor_breaks=lbw_order_stats,labels=c(1:7,seq(10,60,by=10),67:71))+
scale_color_gradient(low="white",high="black",limits=c(0,1),guide=FALSE)+
theme_bw()+theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank()) +
xlab("Rank") + ggtitle("County Ranks by Rank Frequency")
#real data, weighting, indiv ranking vs joint ranking & compromises (10/8)
#Step 1: Run wi_ranking_Ron_092418.R
#Step 2: add weights
N = 71
rankPriority = c("top", "bottom")
rankSteepness = c(0, 0.0001, 0.001, 0.01,  0.1, 0.3, .5, .7, .9) #rankWeights
rankWeights <- as.data.frame(matrix(nrow = 0, ncol = 3))
names(rankWeights) <- c("rw", "rankPriority", "rankSteepness")
for (rp in rankPriority){
for (rs in rankSteepness){
rw <- list(as.double(RankingWeights(numItems = N, priority = rp, steepness = rs)))
rankWeights[nrow(rankWeights) + 1,] <- list(I(rw), rp, rs)
}
}
#Step 3: Rank
lbw_wi$y <- lbw_wi$lbw
lbw_wi$n <- lbw_wi$births
lbw_wi$item <- lbw_wi$county
post <- PostSamplesEB(lbw_wi) #uses lbw_wi
WeightedLossRanking(sampleMatrix = post, parameter = parameter, loss = 2, #f=iden,
rankWeights = filter(rankWeights, rankPriority == "top", rankSteepness ==9e-01)$rw[[1]])
#Step 4: Viz
#rename for viz
lbw_rank_SEL_rank_joint_opt <- as.numeric(solve_LSAP(SEL_rank)) #jointly optimal ranks
## VISUALIZATIONS ##
#creates data frame for all the things we've calculated above for viz
lbw_results_selr <- data_frame(county=lbw_wi$county, #SEL rank scale DF
LBW_pm=apply(lbw_samples,1,mean),
LBW_LCL=lbw_HPD[,1],
LBW_UCL=lbw_HPD[,2],
LBW_rank_pm=lbw_rank_pm,
LBW_rank_io=lbw_rank_SEL_rank_ind_opt_weighted,
LBW_rank_jo=lbw_rank_SEL_rank_joint_opt,
LBW_rank_LCL=lbw_rank_HPD[,1],
LBW_rank_UCL=lbw_rank_HPD[,2]) %>%
arrange(LBW_rank_jo)
lbw_results_selp <- data_frame(county=lbw_wi$county, #pr scale DF
LBW_pm=apply(lbw_samples,1,mean),
LBW_LCL=lbw_HPD[,1],
LBW_UCL=lbw_HPD[,2],
LBW_rank_io=lbw_rank_SEL_prob_ind_opt,
LBW_rank_jo=lbw_rank_SEL_prob_joint_opt,
LBW_rank_LCL=lbw_rank_HPD[,1],
LBW_rank_UCL=lbw_rank_HPD[,2]) %>%
arrange(LBW_rank_jo)
#creates pr and scales them. Pr(given county at that rank relative to its posterior mode)
#gives realtive prob in rank direction but not relative to other counties
post_ranks <- t(apply(lbw_ranks,1,function(x) table(factor(x,levels=1:71))/max(table(factor(x,levels=1:71)))))
#post_ranks <- t(apply(lbw_ranks,1,function(x) table(factor(x,levels=1:71))/10000)) #real posterior probabilities. issue: greys out most places
#post_ranks <- post_ranks/max(post_ranks) #Q:
post_df <- melt(post_ranks) #makes it long because that's what gg plot needs
post_df$county <- lbw_wi$county[post_df$Var1]
post_df$rank <- post_df$Var2
post_df$pos <- lbw_order_stats[post_df$Var2] #TODO lbw_order_stats doesnt exist yet. needs to be created. post means of rows
post_df$county <- factor(post_df$county,levels=rev(lbw_wi$county[order(lbw_rank_SEL_prob_joint_opt)]),ordered=TRUE)
#puts them in correct order in visualization. Makes this an ordered factor. Reverse is because he wants low at top, high at bottom
#grey scale rank viz #Q
ggplot(post_df,aes(x=rank,y=county,color=value))+
geom_point(pch=15,cex=2)+
scale_y_discrete("") +
scale_x_continuous("",breaks=seq(1,71,by=5)) +
#  scale_x_continuous(breaks=lbw_order_stats[c(1:7,seq(10,60,by=10),67:71)],minor_breaks=lbw_order_stats,labels=c(1:7,seq(10,60,by=10),67:71))+
scale_color_gradient(low="white",high="black",limits=c(0,1),guide=FALSE)+
theme_bw()+theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank()) +
xlab("Rank") + ggtitle("County Ranks by Rank Frequency")
#Step 3: create weighted ranking visualizations
#add weights
#Step 4: Viz
#rename for viz
lbw_rank_SEL_rank_joint_opt_weighted <- as.numeric(solve_LSAP(SEL_rank)) #jointly optimal ranks
#creates data frame for all the things we've calculated above for viz
lbw_results_selr_weighted <- data_frame(county=lbw_wi$county, #SEL rank scale DF
LBW_pm=apply(lbw_samples,1,mean),
LBW_LCL=lbw_HPD[,1],
LBW_UCL=lbw_HPD[,2],
LBW_rank_pm=lbw_rank_pm,
LBW_rank_io=lbw_rank_SEL_rank_ind_opt_weighted,
LBW_rank_jo=lbw_rank_SEL_rank_joint_opt,
LBW_rank_LCL=lbw_rank_HPD[,1],
LBW_rank_UCL=lbw_rank_HPD[,2]) %>%
arrange(LBW_rank_jo)
#Step 4: Viz
#rename for viz
lbw_rank_SEL_rank_joint_opt_weighted <- as.numeric(solve_LSAP(SEL_rank)) #jointly optimal ranks
#creates data frame for all the things we've calculated above for viz
lbw_results_selr_weighted <- data_frame(county=lbw_wi$county, #SEL rank scale DF
LBW_pm=apply(lbw_samples,1,mean),
LBW_LCL=lbw_HPD[,1],
LBW_UCL=lbw_HPD[,2],
LBW_rank_pm=lbw_rank_pm,
LBW_rank_io=lbw_rank_SEL_rank_ind_opt,
LBW_rank_jo=lbw_rank_SEL_rank_joint_opt_weighted,
LBW_rank_LCL=lbw_rank_HPD[,1],
LBW_rank_UCL=lbw_rank_HPD[,2]) %>%
arrange(LBW_rank_jo)
#creates pr and scales them. Pr(given county at that rank relative to its posterior mode)
#gives realtive prob in rank direction but not relative to other counties
post_ranks <- t(apply(lbw_ranks,1,function(x) table(factor(x,levels=1:71))/max(table(factor(x,levels=1:71)))))
#post_ranks <- t(apply(lbw_ranks,1,function(x) table(factor(x,levels=1:71))/10000)) #real posterior probabilities. issue: greys out most places
#post_ranks <- post_ranks/max(post_ranks) #Q:
post_df <- melt(post_ranks) #makes it long because that's what gg plot needs
post_df$county <- lbw_wi$county[post_df$Var1]
post_df$rank <- post_df$Var2
post_df$pos <- lbw_order_stats[post_df$Var2] #TODO lbw_order_stats doesnt exist yet. needs to be created. post means of rows
post_df$county <- factor(post_df$county,levels=rev(lbw_wi$county[order(lbw_rank_SEL_prob_joint_opt_weighted)]),ordered=TRUE)
#creates pr and scales them. Pr(given county at that rank relative to its posterior mode)
#gives realtive prob in rank direction but not relative to other counties
post_ranks <- t(apply(lbw_ranks,1,function(x) table(factor(x,levels=1:71))/max(table(factor(x,levels=1:71)))))
#post_ranks <- t(apply(lbw_ranks,1,function(x) table(factor(x,levels=1:71))/10000)) #real posterior probabilities. issue: greys out most places
#post_ranks <- post_ranks/max(post_ranks) #Q:
post_df <- melt(post_ranks) #makes it long because that's what gg plot needs
post_df$county <- lbw_wi$county[post_df$Var1]
post_df$rank <- post_df$Var2
#post_df$pos <- lbw_order_stats[post_df$Var2] #TODO lbw_order_stats doesnt exist yet. needs to be created:posterior means of rows
post_df$county <- factor(post_df$county,levels=rev(lbw_wi$county[order(lbw_rank_SEL_prob_joint_opt_weighted)]),ordered=TRUE)
#post_df$pos <- lbw_order_stats[post_df$Var2] #TODO lbw_order_stats doesnt exist yet. needs to be created:posterior means of rows
post_df$county <- factor(post_df$county,levels=rev(lbw_wi$county[order(lbw_rank_SEL_rank_joint_opt_weighted)]),ordered=TRUE)
#grey scale rank viz #Q
ggplot(post_df,aes(x=rank,y=county,color=value))+
geom_point(pch=15,cex=2)+
scale_y_discrete("") +
scale_x_continuous("",breaks=seq(1,71,by=5)) +
#  scale_x_continuous(breaks=lbw_order_stats[c(1:7,seq(10,60,by=10),67:71)],minor_breaks=lbw_order_stats,labels=c(1:7,seq(10,60,by=10),67:71))+
scale_color_gradient(low="white",high="black",limits=c(0,1),guide=FALSE)+
theme_bw()+theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank()) +
xlab("Rank") + ggtitle("County Ranks by Rank Frequency")
#Step 3: create weighted ranking visualizations
