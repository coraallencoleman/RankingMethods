#   saves .RData of settings, totalLoss, and ranking
#
# Dependencies: rstanarm, clue
rankWeights <- as.data.frame(matrix(nrow = 0, ncol = 3))
names(rankWeights) <- c("rw", "rankPriority", "rankSteepness")
for (rp in rankPriority){
for (rs in rankSteepness){
rw <- list(as.double(RankingWeights(numItems = N, priority = rp, steepness = rs)))
rankWeights[nrow(rankWeights) + 1,] <- list(I(rw), rp, rs)
}
}
#push ps closer in debugging or make n small enough (keep making smaller)
# as we increase sample size, it'll become clearer
#TODO dont worry about random for now. The sample size being fixed is of interest. What happens when tail has lots of small samples,
#lots of big samples. Eventually, some scenarios where its mixed, but we'll mostly make this fixed later
settings <- SelectNP(N, a_p, b_p, n_min, n_max, a_n, b_n, n_assignment_method) #this happens once per experiment
for (i in 1:n_sim){   #for each simulation
data <- SimData(settings)
post <- PostSamplesEB(data)
for (l in loss){ #loss types square and absolute
#for (iden in f){
for (rp in rankPriority){
for (rs in rankSteepness){
ranks <- list()
rankFunctionResult <- WeightedLossRanking(sampleMatrix = post, parameter = parameter, loss = l, #f=iden,
rankWeights = filter(rankWeights, rankPriority == rp, rankSteepness == rs)$rw[[1]])
totalLoss <- as.numeric(sum(rankFunctionResult[[1]])) #this is an nxn rank matrix, so loss = sum(matrix)
ranks <- list(as.integer(rankFunctionResult[[2]]))
row <- c(i, N, a_p, b_p, n_min, n_max, a_n, b_n,
n_assignment_method,
rp, rs,"identity", l, totalLoss, "placeholder", "placeholder")
currResults[nrow(currResults) + 1, ] <- row
currResults$ranking[nrow(currResults)] <- ranks
currResults[[nrow(currResults), 16]] <- data ##save true data (SimData)
}
#  }
}
}
}
return(currResults)
}
# A testing metric for use with simulated data
##function metric to see if rankObject's top ranked items match true top items MATRIX
#TODO FIX this is created a list of 10 logicals NOT five or fifteen
RankMetric <- function(rankObject = NULL, order = "largest", topN = 5){
# function metric to see how much of our top N includes true top N
# note: correct order is always item number because SelectNP assigns true p in order
#
# Args:
#   rankObject: an output of WeightedLossRanking.
#   originalData: a data frame with column of item IDs, n, true probabilities
#   order: largest (largest to smallest) or smallest (smallest to largest)
#   topN: an integer number of top items to compare
#
# Returns:
#   logical vector
#
# Dependencies: rstan, clue, dplyr
ranking <- as.integer(rankObject[[1]][1:topN])
return(1:topN %in% ranking)
}
RankMetricStrict <- function(rankObject = NULL, order = "largest", topN = 5){
# function metric to see how much of top N is correctly ranked (order matters here)
# (more strict metric than RankMetric)
# note: correct order is always item number because SelectNP assigns true p in order
#
# Args:
#   rankObject: an output of WeightedLossRanking.
#   data: a data frame with column of item IDs, n, true probabilities TODO: do we actually need this? correct rank always 1:N
#   order: largest (largest to smallest) or smallest (smallest to largest)
#   topN: an integer number of top items to compare
#
# Returns:
#   logical
#
# Dependencies: rstan, clue, dplyr
ranking <- as.integer(rankObject[[1]][1:topN])
return(1:topN == ranking)
}
library(tidyverse)
library(reshape2)
library(coda)
library(clue)
setwd("/Users/cora/git_repos/RankingMethods/")
lbw_wi <- read_csv("lbw_wi.csv")
#remove missing, then create N normal birth weight, % LBW columns
lbw_wi <- lbw_wi %>% mutate(nbw=births-lbw,perc_lbw=lbw/births*100) %>% filter(!is.na(lbw))
#sample from LBW beta distribution using lbw as shape1, nbw as shape2 Q
lbw_samples <- replicate(10000,
rbeta(n = 71, shape1=lbw_wi$lbw, shape2=lbw_wi$nbw))
#if p follows beta(a,b) and y follows bin(n,p) then p|y follows beta(a+y, b+n-y)
#This is an improper prior (a,b cannot be 0), but this becomes a proper posterior
#as long as you have > 0 successes and > 0 failures. close to doing a bootstrap. like a null model.
lbw_ranks <- apply(lbw_samples,2,rank) #Q doesnt this flip? I use 1 here in WeightedLossRanking function
lbw_order <- apply(lbw_samples,2,sort)
#when you do things by rows (2), it doesn't flip. Always outputs same.
#creates 71 X 2 MATRIX of HPD intervals
lbw_HPD <- t(apply(lbw_samples,1,function(x) HPDinterval(mcmc(x))))
lbw_rank_HPD <- t(apply(lbw_ranks,1,function(x) HPDinterval(mcmc(x))))
lbw_order_HPD <- t(apply(lbw_order,1,function(x) HPDinterval(mcmc(x))))
#calculating loss on rank scale
SEL_rank <- matrix(NA,71,71) #square error loss
for (i in 1:71) {
for (j in 1:71) {
SEL_rank[i,j] <- mean((lbw_ranks[i,]-j)^2)
}
}
#calculating loss on prob scale?
SEL_prob <- matrix(NA,71,71)
for (i in 1:71) {
for (j in 1:71) {
SEL_prob[i,j] <- mean((lbw_samples[i,]-lbw_order[j,])^2)
}
}
lbw_rank_pm <- apply(lbw_ranks,1,mean) #posterior mean
lbw_rank_SEL_rank_ind_opt <- apply(SEL_rank,1,which.min) #individually optimal ranks
lbw_rank_SEL_rank_joint_opt <- as.numeric(solve_LSAP(SEL_rank)) #jointly optimal ranks
lbw_rank_SEL_prob_ind_opt <- apply(SEL_prob,1,which.min) #individually optimal ranks on pr scale
lbw_rank_SEL_prob_joint_opt <- as.numeric(solve_LSAP(SEL_prob)) #jointly optimal ranks on pr scale
#Q: to get comparison probabilities to compare. What's pr that pepin has sm rate than mil
#creates 71x71 matrix Pr(county i LBW % <county j LBW %) This is comparison-wise loss.
#a potential loss is pr of those comparisons you get right = sum(upper triangle).
#want to min(sum lower triangle). There isnt a clear algorithm that solves this.
#Diagonal should be .5 but its 0. this only matters if looking for min
prob1 <- matrix(NA,71,71)
for (i in 1:71) {
for (j in 1:71) {
prob1[i,j] <- mean(lbw_samples[i,]<lbw_samples[j,])
}
}
#prob1a <- prob1[order(rank2a),order(rank2a)]
## VISUALIZATIONS ##
#creates data frame for all the things we've calculated above for viz
lbw_results_selr <- data_frame(county=lbw_wi$county, #SEL rank scale DF
LBW_pm=apply(lbw_samples,1,mean),
LBW_LCL=lbw_HPD[,1],
LBW_UCL=lbw_HPD[,2],
LBW_rank_pm=lbw_rank_pm,
LBW_rank_io=lbw_rank_SEL_rank_ind_opt,
LBW_rank_jo=lbw_rank_SEL_rank_joint_opt,
LBW_rank_LCL=lbw_rank_HPD[,1],
LBW_rank_UCL=lbw_rank_HPD[,2]) %>%
arrange(LBW_rank_jo)
lbw_results_selp <- data_frame(county=lbw_wi$county, #pr scale DF
LBW_pm=apply(lbw_samples,1,mean),
LBW_LCL=lbw_HPD[,1],
LBW_UCL=lbw_HPD[,2],
LBW_rank_io=lbw_rank_SEL_prob_ind_opt,
LBW_rank_jo=lbw_rank_SEL_prob_joint_opt,
LBW_rank_LCL=lbw_rank_HPD[,1],
LBW_rank_UCL=lbw_rank_HPD[,2]) %>%
arrange(LBW_rank_jo)
#creates pr and scales them. Pr(given county at that rank relative to its posterior mode)
#gives realtive prob in rank direction but not relative to other counties
post_ranks <- t(apply(lbw_ranks,1,function(x) table(factor(x,levels=1:71))/max(table(factor(x,levels=1:71)))))
#post_ranks <- t(apply(lbw_ranks,1,function(x) table(factor(x,levels=1:71))/10000)) #real posterior probabilities. issue: greys out most places
#post_ranks <- post_ranks/max(post_ranks) #Q:
post_df <- melt(post_ranks) #makes it long because that's what gg plot needs
post_df$county <- lbw_wi$county[post_df$Var1]
post_df$rank <- post_df$Var2
post_df$pos <- lbw_order_stats[post_df$Var2] #TODO lbw_order_stats doesnt exist yet. needs to be created. post means of rows
post_df$county <- factor(post_df$county,levels=rev(lbw_wi$county[order(lbw_rank_SEL_prob_joint_opt)]),ordered=TRUE)
#puts them in correct order in visualization. Makes this an ordered factor. Reverse is because he wants low at top, high at bottom
#grey scale rank viz #Q
ggplot(post_df,aes(x=rank,y=county,color=value))+
geom_point(pch=15,cex=2)+
scale_y_discrete("") +
scale_x_continuous("",breaks=seq(1,71,by=5)) +
#  scale_x_continuous(breaks=lbw_order_stats[c(1:7,seq(10,60,by=10),67:71)],minor_breaks=lbw_order_stats,labels=c(1:7,seq(10,60,by=10),67:71))+
scale_color_gradient(low="white",high="black",limits=c(0,1),guide=FALSE)+
theme_bw()+theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank()) +
xlab("Rank") + ggtitle("County Ranks by Rank Frequency")
#Step 2a: add rank weights (1 for 1:10)
N = 71
rankPriority = c("top", "bottom")
rankSteepness = c(0, 0.0001, 0.001, 0.01,  0.1, 0.3, .5, .7, .9) #rankWeights
rankWeights = c(rep(1, times = 10), rep(0, times = 61))
rankWeights
dim(post)
#Step 3: Rank
lbw_wi$y <- lbw_wi$lbw
lbw_wi$n <- lbw_wi$births
lbw_wi$item <- lbw_wi$county
post <- PostSamplesEB(lbw_wi) #uses lbw_wi
#Step 1: Run wi_ranking_Ron_092418.R and:
lbw_wi$y <- lbw_wi$lbw
lbw_wi$n <- lbw_wi$births
lbw_wi$item <- lbw_wi$county
post <- PostSamplesEB(lbw_wi) #uses lbw_wi
dim(post)
#Step 2b: add item weights 1/variance
#get variance of each, make into a vector
inv_variance = lapply(post, var)
dim(inv_variance)
length(inv_variance)
#Step 2b: add item weights 1/variance
#get variance of each, make into a vector
inv_variance = sapply(post, var)
length(inv_variance)
#Step 2b: add item weights 1/variance
#get variance of each, make into a vector
inv_variance = sapply(post, var())
#Step 2b: add item weights 1/variance
#get variance of each, make into a vector
inv_variance = lapply(post, mean)
inv_var(post)
#Step 2b: add item weights 1/variance
#get variance of each, make into a vector
inv_variance = lapply(post, mean)
#Step 2b: add item weights 1/variance
#get variance of each, make into a vector
inv_variance = apply(post, 2, mean)
#Step 2b: add item weights 1/variance
#get variance of each, make into a vector
inv_variance = apply(post, 2, var)
#Step 2b: add item weights 1/variance
#get variance of each, make into a vector
inv_variance = apply(post, 2, var)
itemWeights = inv_variance
rankEven_itemInvVar <- WeightedLossRanking(sampleMatrix = post, parameter = parameter, loss = 2, #f=iden,
#rankWeights = rankWeights,
itemWeights = itemWeights)
itemWeights
rankEven_itemInvVar <- WeightedLossRanking(sampleMatrix = post, parameter = parameter, loss = 2, #f=iden,
#rankWeights = rankWeights,
itemWeights = itemWeights)
source('~/git_repos/RankingMethods/ranking_function.r')
#Step 2b: add item weights 1/variance
#get variance of each, make into a vector
inv_variance = apply(post, 2, var)
itemWeights = inv_variance
rankEven_itemInvVar <- WeightedLossRanking(sampleMatrix = post, parameter = parameter, loss = 2, #f=iden,
#rankWeights = rankWeights,
itemWeights = itemWeights)
ranktop10_itemInvVar <- WeightedLossRanking(sampleMatrix = post, parameter = parameter, loss = 2, #f=iden,
rankWeights = rankWeights,
itemWeights = itemWeights)
rankEven_itemInvVar
#Step 4: Visualizations comparing two ways
lbw_results_selr_weighted <- data_frame(county=lbw_wi$county, #SEL rank scale DF
LBW_pm=apply(lbw_samples,1,mean),
LBW_LCL=lbw_HPD[,1],
LBW_UCL=lbw_HPD[,2],
LBW_rank_pm=lbw_rank_pm,
#LBW_rank_io=lbw_rank_SEL_rank_ind_opt,
LBW_rank_jo=rankEven_itemInvVar,
LBW_rank_LCL=lbw_rank_HPD[,1],
LBW_rank_UCL=lbw_rank_HPD[,2]) %>%
arrange(LBW_rank_jo)
#Step 4: Visualizations comparing two ways
lbw_results_selr_weighted <- data_frame(county=lbw_wi$county, #SEL rank scale DF
LBW_pm=apply(lbw_samples,1,mean),
LBW_LCL=lbw_HPD[,1],
LBW_UCL=lbw_HPD[,2],
LBW_rank_pm=lbw_rank_pm,
#LBW_rank_io=lbw_rank_SEL_rank_ind_opt,
LBW_rank_jo=as.numeric(rankEven_itemInvVar),
LBW_rank_LCL=lbw_rank_HPD[,1],
LBW_rank_UCL=lbw_rank_HPD[,2]) %>%
arrange(LBW_rank_jo)
rankEven_itemInvVar[2]
rankEven_itemInvVar[[2]]
as.numeric(rankEven_itemInvVar[[2]])
#Step 4: Visualizations comparing two ways
lbw_results_selr_weighted <- data_frame(county=lbw_wi$county, #SEL rank scale DF
LBW_pm=apply(lbw_samples,1,mean),
LBW_LCL=lbw_HPD[,1],
LBW_UCL=lbw_HPD[,2],
LBW_rank_pm=lbw_rank_pm,
#LBW_rank_io=lbw_rank_SEL_rank_ind_opt,
LBW_rank_jo=as.numeric(rankEven_itemInvVar[[2]]),
LBW_rank_LCL=lbw_rank_HPD[,1],
LBW_rank_UCL=lbw_rank_HPD[,2]) %>%
arrange(LBW_rank_jo)
#post_ranks <- t(apply(lbw_ranks,1,function(x) table(factor(x,levels=1:71))/10000)) #real posterior probabilities. issue: greys out most places
#post_ranks <- post_ranks/max(post_ranks) #Q:
post_df <- melt(post_ranks) #makes it long because that's what gg plot needs
post_df$county <- lbw_wi$county[post_df$Var1]
post_df$rank <- post_df$Var2
#post_df$pos <- lbw_order_stats[post_df$Var2] #TODO lbw_order_stats doesnt exist yet. needs to be created:posterior means of rows
post_df$county <- factor(post_df$county,levels=rev(lbw_wi$county[order(LBW_rank_jo)]),ordered=TRUE) #puts them in correct order in visualization. Makes this an ordered factor. Reverse is because he wants low at top, high at bottom
#Step 4: Visualizations comparing two ways
lbw_results_rankEven_itemInvVar <- data_frame(county=lbw_wi$county, #SEL rank scale DF
LBW_pm=apply(lbw_samples,1,mean),
LBW_LCL=lbw_HPD[,1],
LBW_UCL=lbw_HPD[,2],
LBW_rank_pm=lbw_rank_pm,
#LBW_rank_io=lbw_rank_SEL_rank_ind_opt,
LBW_rank_jo=as.numeric(rankEven_itemInvVar[[2]]),
LBW_rank_LCL=lbw_rank_HPD[,1],
LBW_rank_UCL=lbw_rank_HPD[,2]) %>%
arrange(LBW_rank_jo)
#grey scale rank viz
postscript("plots/post_SEL_weighted_rankEven_itemInvVar.eps")
#post_df$pos <- lbw_order_stats[post_df$Var2] #TODO lbw_order_stats doesnt exist yet. needs to be created:posterior means of rows
post_df$county <- factor(post_df$county,levels=rev(lbw_wi$county[order(LBW_rank_jo)]),ordered=TRUE) #puts them in correct order in visualization. Makes this an ordered factor. Reverse is because he wants low at top, high at bottom
#post_df$pos <- lbw_order_stats[post_df$Var2] #TODO lbw_order_stats doesnt exist yet. needs to be created:posterior means of rows
post_df$county <- factor(post_df$county,levels=rev(lbw_wi$county[order(as.numeric(rankEven_itemInvVar[[2]]))]),ordered=TRUE) #puts them in correct order in visualization. Makes this an ordered factor. Reverse is because he wants low at top, high at bottom
#grey scale rank viz
postscript("plots/post_SEL_weighted_rankEven_itemInvVar.eps")
ggplot(post_df,aes(x=rank,y=county,color=value))+
geom_point(pch=15,cex=2)+
scale_y_discrete("") +
scale_x_continuous("",breaks=seq(1,71,by=5)) +
scale_color_gradient(low="white",high="black",limits=c(0,1),guide=FALSE)+
theme_bw()+theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank()) +
xlab("Rank") + ggtitle("County Ranks by Rank Frequency")
dev.off()
#viz 2
post_df$county <- factor(post_df$county,levels=rev(lbw_wi$county[order(as.numeric(ranktop10_itemInvVar[[2]]))]),ordered=TRUE)
postscript("plots/post_SEL_weighted_ranktop10_itemInvVar.eps")
ggplot(post_df,aes(x=rank,y=county,color=value))+
geom_point(pch=15,cex=2)+
scale_y_discrete("") +
scale_x_continuous("",breaks=seq(1,71,by=5)) +
scale_color_gradient(low="white",high="black",limits=c(0,1),guide=FALSE)+
theme_bw()+theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank()) +
xlab("Rank") + ggtitle("County Ranks by Rank Frequency")
dev.off()
rankWeightsTop10 = c(rep(1, times = 10), rep(0, times = 61))
ranktop10_itemInvVar <- WeightedLossRanking(sampleMatrix = post, parameter = parameter, loss = 2, #f=iden,
rankWeights = rankWeightsTop10,
itemWeights = itemWeights)
rankgrad_itemInvVar <- WeightedLossRanking(sampleMatrix = post, parameter = parameter, loss = 2, #f=iden,
rankWeights = filter(rankWeights, rankPriority == "top", rankSteepness ==9e-01)$rw[[1]],,
itemWeights = itemWeights)
rankWeightsTop10 = c(rep(1, times = 10), rep(0, times = 61))
#gradual weighting
rankPriority = c("top", "bottom")
rankSteepness = c(0, 0.0001, 0.001, 0.01,  0.1, 0.3, .5, .7, .9) #rankWeights
rankWeights <- as.data.frame(matrix(nrow = 0, ncol = 3))
names(rankWeights) <- c("rw", "rankPriority", "rankSteepness")
for (rp in rankPriority){
for (rs in rankSteepness){
rw <- list(as.double(RankingWeights(numItems = N, priority = rp, steepness = rs)))
rankWeights[nrow(rankWeights) + 1,] <- list(I(rw), rp, rs)
}
}
rankgrad_itemInvVar <- WeightedLossRanking(sampleMatrix = post, parameter = parameter, loss = 2, #f=iden,
rankWeights = filter(rankWeights, rankPriority == "top", rankSteepness ==9e-01)$rw[[1]],,
itemWeights = itemWeights)
rankgrad_itemInvVar <- WeightedLossRanking(sampleMatrix = post, parameter = parameter, loss = 2, #f=iden,
rankWeights = filter(rankWeights, rankPriority == "top", rankSteepness ==9e-01)$rw[[1]],
itemWeights = itemWeights)
#viz 3
post_df$county <- factor(post_df$county,levels=rev(lbw_wi$county[order(as.numeric(rankgrad_itemInvVar[[2]]))]),ordered=TRUE)
postscript("plots/post_SEL_weighted_rankgrad_itemInvVar.eps")
ggplot(post_df,aes(x=rank,y=county,color=value))+
geom_point(pch=15,cex=2)+
scale_y_discrete("") +
scale_x_continuous("",breaks=seq(1,71,by=5)) +
scale_color_gradient(low="white",high="black",limits=c(0,1),guide=FALSE)+
theme_bw()+theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank()) +
xlab("Rank") + ggtitle("County Ranks by Rank Frequency")
dev.off()
#Step 2b: add item weights 1/variance
#get variance of each, make into a vector
variance = apply(post, 2, var)
itemWeights = 1/variance
1/.006
itemWeights = 1/variance
#real data, weighting, indiv ranking vs joint ranking & compromises (10/8)
#Step 1: Run wi_ranking_Ron_092418.R and:
lbw_wi$y <- lbw_wi$lbw
lbw_wi$n <- lbw_wi$births
lbw_wi$item <- lbw_wi$county
post <- PostSamplesEB(lbw_wi) #uses lbw_wi
#Step 2a: add rank weights (1 for 1:10)
N = 71
rankWeightsTop10 = c(rep(1, times = 10), rep(0, times = 61))
#gradual weighting
rankPriority = c("top", "bottom")
rankSteepness = c(0, 0.0001, 0.001, 0.01,  0.1, 0.3, .5, .7, .9) #rankWeights
rankWeights <- as.data.frame(matrix(nrow = 0, ncol = 3))
names(rankWeights) <- c("rw", "rankPriority", "rankSteepness")
for (rp in rankPriority){
for (rs in rankSteepness){
rw <- list(as.double(RankingWeights(numItems = N, priority = rp, steepness = rs)))
rankWeights[nrow(rankWeights) + 1,] <- list(I(rw), rp, rs)
}
}
#Step 2b: add item weights 1/variance
#get variance of each, make into a vector
variance = apply(post, 2, var)
itemWeights = 1/variance
#Step 3: Rank
rankEven_itemInvVar <- WeightedLossRanking(sampleMatrix = post, parameter = parameter, loss = 2, #f=iden,
#rankWeights = rankWeights,
itemWeights = itemWeights)
ranktop10_itemInvVar <- WeightedLossRanking(sampleMatrix = post, parameter = parameter, loss = 2, #f=iden,
rankWeights = rankWeightsTop10,
itemWeights = itemWeights)
rankgrad_itemInvVar <- WeightedLossRanking(sampleMatrix = post, parameter = parameter, loss = 2, #f=iden,
rankWeights = filter(rankWeights, rankPriority == "top", rankSteepness ==9e-01)$rw[[1]],
itemWeights = itemWeights)
#Step 4: Visualizations comparing two ways
lbw_results_rankEven_itemInvVar <- data_frame(county=lbw_wi$county, #SEL rank scale DF
LBW_pm=apply(lbw_samples,1,mean),
LBW_LCL=lbw_HPD[,1],
LBW_UCL=lbw_HPD[,2],
LBW_rank_pm=lbw_rank_pm,
#LBW_rank_io=lbw_rank_SEL_rank_ind_opt,
LBW_rank_jo=as.numeric(rankEven_itemInvVar[[2]]),
LBW_rank_LCL=lbw_rank_HPD[,1],
LBW_rank_UCL=lbw_rank_HPD[,2]) %>%
arrange(LBW_rank_jo)
#creates pr and scales them. Pr(given county at that rank relative to its posterior mode) #gives realtive prob in rank direction but not relative to other counties
post_ranks <- t(apply(lbw_ranks,1,function(x) table(factor(x,levels=1:71))/max(table(factor(x,levels=1:71)))))
#post_ranks <- t(apply(lbw_ranks,1,function(x) table(factor(x,levels=1:71))/10000)) #real posterior probabilities. issue: greys out most places
#post_ranks <- post_ranks/max(post_ranks) #Q:
post_df <- melt(post_ranks) #makes it long because that's what gg plot needs
post_df$county <- lbw_wi$county[post_df$Var1]
post_df$rank <- post_df$Var2
#post_df$pos <- lbw_order_stats[post_df$Var2] #TODO lbw_order_stats doesnt exist yet. needs to be created:posterior means of rows
post_df$county <- factor(post_df$county,levels=rev(lbw_wi$county[order(as.numeric(rankEven_itemInvVar[[2]]))]),ordered=TRUE) #puts them in correct order in visualization. Makes this an ordered factor. Reverse is because he wants low at top, high at bottom
#viz 1
postscript("plots/post_SEL_weighted_rankEven_itemInvVar.eps")
ggplot(post_df,aes(x=rank,y=county,color=value))+
geom_point(pch=15,cex=2)+
scale_y_discrete("") +
scale_x_continuous("",breaks=seq(1,71,by=5)) +
scale_color_gradient(low="white",high="black",limits=c(0,1),guide=FALSE)+
theme_bw()+theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank()) +
xlab("Rank") + ggtitle("County Ranks by Rank Frequency")
dev.off()
#viz 2
post_df$county <- factor(post_df$county,levels=rev(lbw_wi$county[order(as.numeric(ranktop10_itemInvVar[[2]]))]),ordered=TRUE)
postscript("plots/post_SEL_weighted_ranktop10_itemInvVar.eps")
ggplot(post_df,aes(x=rank,y=county,color=value))+
geom_point(pch=15,cex=2)+
scale_y_discrete("") +
scale_x_continuous("",breaks=seq(1,71,by=5)) +
scale_color_gradient(low="white",high="black",limits=c(0,1),guide=FALSE)+
theme_bw()+theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank()) +
xlab("Rank") + ggtitle("County Ranks by Rank Frequency")
dev.off()
#viz 3
post_df$county <- factor(post_df$county,levels=rev(lbw_wi$county[order(as.numeric(rankgrad_itemInvVar[[2]]))]),ordered=TRUE)
postscript("plots/post_SEL_weighted_rankgrad_itemInvVar.eps")
ggplot(post_df,aes(x=rank,y=county,color=value))+
geom_point(pch=15,cex=2)+
scale_y_discrete("") +
scale_x_continuous("",breaks=seq(1,71,by=5)) +
scale_color_gradient(low="white",high="black",limits=c(0,1),guide=FALSE)+
theme_bw()+theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank()) +
xlab("Rank") + ggtitle("County Ranks by Rank Frequency")
dev.off()
#old visualizations
#rename for viz
lbw_rank_SEL_rank_joint_opt_weighted <- as.numeric(solve_LSAP(SEL_rank)) #jointly optimal ranks
## VISUALIZATIONS ##
#creates data frame for all the things we've calculated above for viz
lbw_results_selr_weighted <- data_frame(county=lbw_wi$county, #SEL rank scale DF
LBW_pm=apply(lbw_samples,1,mean),
LBW_LCL=lbw_HPD[,1],
LBW_UCL=lbw_HPD[,2],
LBW_rank_pm=lbw_rank_pm,
LBW_rank_io=lbw_rank_SEL_rank_ind_opt,
LBW_rank_jo=lbw_rank_SEL_rank_joint_opt_weighted,
LBW_rank_LCL=lbw_rank_HPD[,1],
LBW_rank_UCL=lbw_rank_HPD[,2]) %>%
arrange(LBW_rank_jo)
#creates pr and scales them. Pr(given county at that rank relative to its posterior mode)
#gives realtive prob in rank direction but not relative to other counties
post_ranks <- t(apply(lbw_ranks,1,function(x) table(factor(x,levels=1:71))/max(table(factor(x,levels=1:71)))))
#post_ranks <- t(apply(lbw_ranks,1,function(x) table(factor(x,levels=1:71))/10000)) #real posterior probabilities. issue: greys out most places
#post_ranks <- post_ranks/max(post_ranks) #Q:
post_df <- melt(post_ranks) #makes it long because that's what gg plot needs
post_df$county <- lbw_wi$county[post_df$Var1]
post_df$rank <- post_df$Var2
#post_df$pos <- lbw_order_stats[post_df$Var2] #TODO lbw_order_stats doesnt exist yet. needs to be created:posterior means of rows
post_df$county <- factor(post_df$county,levels=rev(lbw_wi$county[order(lbw_rank_SEL_rank_joint_opt_weighted)]),ordered=TRUE)
#puts them in correct order in visualization. Makes this an ordered factor. Reverse is because he wants low at top, high at bottom
# lbw_results_selp <- data_frame(county=lbw_wi$county, #pr scale DF
#                                LBW_pm=apply(lbw_samples,1,mean),
#                                LBW_LCL=lbw_HPD[,1],
#                                LBW_UCL=lbw_HPD[,2],
#                                LBW_rank_io=lbw_rank_SEL_prob_ind_opt,
#                                LBW_rank_jo=lbw_rank_SEL_prob_joint_opt,
#                                LBW_rank_LCL=lbw_rank_HPD[,1],
#                                LBW_rank_UCL=lbw_rank_HPD[,2]) %>%
#   arrange(LBW_rank_jo)
#creates pr and scales them. Pr(given county at that rank relative to its posterior mode)
#gives realtive prob in rank direction but not relative to other counties
post_ranks <- t(apply(lbw_ranks,1,function(x) table(factor(x,levels=1:71))/max(table(factor(x,levels=1:71)))))
#post_ranks <- t(apply(lbw_ranks,1,function(x) table(factor(x,levels=1:71))/10000)) #real posterior probabilities. issue: greys out most places
#post_ranks <- post_ranks/max(post_ranks) #Q:
post_df <- melt(post_ranks) #makes it long because that's what gg plot needs
post_df$county <- lbw_wi$county[post_df$Var1]
post_df$rank <- post_df$Var2
#post_df$pos <- lbw_order_stats[post_df$Var2] #TODO lbw_order_stats doesnt exist yet. needs to be created:posterior means of rows
post_df$county <- factor(post_df$county,levels=rev(lbw_wi$county[order(lbw_rank_SEL_rank_joint_opt_weighted)]),ordered=TRUE)
#puts them in correct order in visualization. Makes this an ordered factor. Reverse is because he wants low at top, high at bottom
#grey scale rank viz #SQUARE ERROR LOSS WEIGHTED
postscript("plots/post_SEL_weighted.eps")
ggplot(post_df,aes(x=rank,y=county,color=value))+
geom_point(pch=15,cex=2)+
scale_y_discrete("") +
scale_x_continuous("",breaks=seq(1,71,by=5)) +
#  scale_x_continuous(breaks=lbw_order_stats[c(1:7,seq(10,60,by=10),67:71)],minor_breaks=lbw_order_stats,labels=c(1:7,seq(10,60,by=10),67:71))+
scale_color_gradient(low="white",high="black",limits=c(0,1),guide=FALSE)+
theme_bw()+theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank()) +
xlab("Rank") + ggtitle("County Ranks by Rank Frequency")
dev.off()
#Step 3: create weighted ranking visualizations
#add weights
#Step 2b: add item weights 1/variance
#get variance of each, make into a vector
variance = apply(post, 2, var)
itemWeights = 1/variance
itemWeights
variance
