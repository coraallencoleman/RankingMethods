logORage2 <- log((age2[1,1]*age2[2,2])/(age2[1,2]*age2[2,1])); logORage2
varlogOR2 <- (1/age2[1,1]+ 1/age2[1,2] + 1/age2[2,1]+1/age2[2,2]); varlogOR2
weights <- c(varlogOR1^(-1)/29.62155, varlogOR2^(-1)/29.62155); weights
Woolf <- (weights[1])*logORage1 + (weights[2])*logORage2
Woolf
WoolfCI <- c(Woolf - 1.96*sqrt((1/(weights[1]+weights[2]))), Woolf + 1.96*sqrt((1/(weights[1]+weights[2]))));WoolfCI
exp(WoolfCI)
weights_MH <- c((age1[2,1]*age1[1,2])/age1[3,3], (age2[2,1]*age2[1,2])/age2[3,3])
weights_MH <- c((age1[2,1]*age1[1,2])/age1[3,3], (age2[2,1]*age2[1,2])/age2[3,3]); weights_MH
MH_estimate <- (age1[1,1]*age1[2,2]/age1[3,3] + age2[1,1]*age2[2,2]/age2[3,3])/(age1[2,1]*age1[1,2]/age1[3,3] + age2[2,1]*age2[1,2]/age2[3,3])
MH_estimate <- (age1[1,1]*age1[2,2]/age1[3,3] + age2[1,1]*age2[2,2]/age2[3,3])/(age1[2,1]*age1[1,2]/age1[3,3] + age2[2,1]*age2[1,2]/age2[3,3]);MH_estimate
U1 <- (age1[1,1] + age1[2,2])/age1[3,3]
U2 <- (age2[1,1] + age2[2,2])/age2[3,3]
U1 <- (age1[1,1] + age1[2,2])/age1[3,3]
U2 <- (age2[1,1] + age2[2,2])/age2[3,3]
R1 <- age1[1,1]*age1[2,2]/age1[3,3]
R2 <- age2[1,1]*age2[2,2]/age2[3,3]
U1 <- (age1[1,1] + age1[2,2])/age1[3,3]
U2 <- (age2[1,1] + age2[2,2])/age2[3,3]
V1 <- (age1[1,2] + age1[2,1])/age1[3,3]
V2 <- (age2[1,2] + age2[2,1])/age2[3,3]
R1 <- age1[1,1]*age1[2,2]/age1[3,3]
R2 <- age2[1,1]*age2[2,2]/age2[3,3]
U1 <- (age1[1,1] + age1[2,2])/age1[3,3]
U2 <- (age2[1,1] + age2[2,2])/age2[3,3]
V1 <- (age1[1,2] + age1[2,1])/age1[3,3]
V2 <- (age2[1,2] + age2[2,1])/age2[3,3]
R1 <- age1[1,1]age1[2,2]/age1[3,3]
MH_logvar <- 0.5*((U1*R1 + U2*R2)/(R1+R2) + ((U1*S1 + V1*R1) + (U2*S2 + V2*R2))/((R1+R2)*(S1+S2)) + (V1*S1 + V2*S2)/(S1+S2)^2)
U1 <- (age1[1,1] + age1[2,2])/age1[3,3]
U2 <- (age2[1,1] + age2[2,2])/age2[3,3]
V1 <- (age1[1,2] + age1[2,1])/age1[3,3]
V2 <- (age2[1,2] + age2[2,1])/age2[3,3]
R1 <- age1[1,1]*age1[2,2]/age1[3,3]
R2 <- age2[1,1]*age2[2,2]/age2[3,3]
S1 <- (age1[1,2]*age1[2,1])/age1[3,3]
S2 <- (age2[1,2] + age2[2,1])/age2[3,3]
MH_logvar <- 0.5*((U1*R1 + U2*R2)/(R1+R2) + ((U1*S1 + V1*R1) + (U2*S2 + V2*R2))/((R1+R2)*(S1+S2)) + (V1*S1 + V2*S2)/(S1+S2)^2)
MH_CI_lower <- log(MH_estimate) - 1.96*(MH_logvar/X2) #X2 from summary above
MH_CI<- c(log(MH_estimate) - 1.96*(MH_logvar/X2), log(MH_estimate) - 1.96*(MH_logvar/X2)) #X2 from summary above
MH_CI
MH_CI<- c(log(MH_estimate) - 1.96*(MH_logvar/X2), log(MH_estimate) + 1.96*(MH_logvar/X2)) #X2 from summary above
MH_CI
log_MH_CI<- c(log(MH_estimate) - 1.96*(MH_logvar/X2), log(MH_estimate) + 1.96*(MH_logvar/X2)) #X2 from summary above
exp(log_MH_CI)
log_MH_CI<- c(log(MH_estimate) - 1.96*(MH_logvar/X2), log(MH_estimate) + 1.96*(MH_logvar/X2)) #X2 from summary above
log_MH_CI
exp(log_MH_CI)
WoolfCI <- c(Woolf - 1.96*sqrt((1/(weights[1]+weights[2]))), Woolf + 1.96*sqrt((1/(weights[1]+weights[2]))));WoolfCI
exp(WoolfCI)
log_MH_CI
Woolf <- (weights[1])*logORage1 + (weights[2])*logORage2
Woolf
WoolfCI <- c(Woolf - 1.96*sqrt((1/(weights[1]+weights[2]))), Woolf + 1.96*sqrt((1/(weights[1]+weights[2]))));WoolfCI
q2 <- data.frame(cases = c(41, 44, 85), controls = c(33, 52, 85), totals = c(74, 96, 170))
#chi square test
ax2 <- chisq.test(q2)
#chi square test
ax2 <- chisq.test(q2);ax2
#chi square test
ax2 <- chisq.test(q2[1:2, 1:2]);ax2
M <- as.table(rbind(c(762, 327, 468), c(484, 239, 477)))
dimnames(M) <- list(gender = c("F", "M"),
party = c("Democrat","Independent", "Republican"))
(Xsq <- chisq.test(M))  # Prints test summary
M
q2
#chi square test
ax2 <- chisq.test(q2[1:2, 1:2], df = 1);ax2
#chi square test
ax2 <- chisq.test(q2[1:2, 1:2]);ax2
(41 - (85*(74/170)))^2/(85*(74/170))
(41 - (85*(74/170)))^2/(85*(74/170)) + (44 - (85*(96/170)))^2)/(85*(96/170)) +
(41 - (85*(74/170)))^2)/(85*(74/170)) + (44 - (85*(96/170)))^2)/(85*(96/170)) +
(41 - (85*74/170))^2/(85*(74/170)) + (44 - (85*(96/170)))^2/(85*(96/170)) +
(33 - 85*(74/170))^2/(85*(74/170)) + (52 - 85*(96/170))^2/(85*96/170)
ax2_check <- (41 - (85*74/170))^2/(85*(74/170)) + (44 - (85*(96/170)))^2/(85*(96/170)) +
(33 - 85*(74/170))^2/(85*(74/170)) + (52 - 85*(96/170))^2/(85*96/170)
ax2_check <- (41 - (85*74/170))^2/(85*(74/170)) + (44 - (85*(96/170)))^2/(85*(96/170)) +
(33 - 85*(74/170))^2/(85*(74/170)) + (52 - 85*(96/170))^2/(85*96/170);ax2_check
#chi square test
ax2 <- chisq.test(q2[1:2, 1:2]);ax2
ax2_check <- (41 - (85*74/170))^2/(85*(74/170)) + (44 - (85*(96/170)))^2/(85*(96/170)) +
(33 - 85*(74/170))^2/(85*(74/170)) + (52 - 85*(96/170))^2/(85*96/170);ax2_check
#chi square test
ax2 <- chisq.test(q2[1:2, 1:2]);ax2
q2[1:2, 1:2]
#chi square test
ax2 <- chisq.test(q2[1:2, 1:2]);ax2
#chi square test
ax2 <- chisq.test(q2[1:2, 1:2], correct = FALSE);ax2
ax2_check <- (41 - (85*74/170))^2/(85*(74/170)) + (44 - (85*(96/170)))^2/(85*(96/170)) +
(33 - 85*(74/170))^2/(85*(74/170)) + (52 - 85*(96/170))^2/(85*96/170);ax2_check
#estimated OR for Hodgkin's Disease
OR_Hodgkins <- (q2[1,1]*q2[2,1])/(q2[1,2]*q2[2,2])
#estimated OR for Hodgkin's Disease
OR_Hodgkins <- (q2[1,1]*q2[2,1])/(q2[1,2]*q2[2,2]); OR_Hodgkins
#estimated OR for Hodgkin's Disease
OR_Hodgkins <- (q2[1,1]/q2[2,1])/(q2[1,2]/q2[2,2]); OR_Hodgkins
var_logOR <- (1/41 + 1/44 + 1/33 + 1/52)
OR_CI <- exp(c(log(OR_Hodgkins) - 1.96*var_logOR, log(OR_Hodgkins) - 1.96*var_logOR));OR_CI
OR_CI <- exp(c(log(OR_Hodgkins) - 1.96*var_logOR, log(OR_Hodgkins) + 1.96*var_logOR));OR_CI
#estimated OR for Hodgkin's Disease
OR_Hodgkins <- (q2[1,1]/q2[2,1])/(q2[1,2]/q2[2,2]); OR_Hodgkins
OR_CI <- exp(c(log(OR_Hodgkins) - 1.96*var_logOR, log(OR_Hodgkins) + 1.96*var_logOR));OR_CI
#read in data
rhc <- read.table("Downloads/rhc.csv",sep=",",header=TRUE)
q2b <- data.frame(cases = c(26, 7), controls = c(15, 37))
q2b <- data.frame(Ton = c(26, 7), notTon = c(15, 37))
q2b
q2b <- data.frame(Ton = c(26, 7), notTon = c(15, 37));q2b
qf(.975)
qf(.975, df = 1)
#CI based on Normal approx for logOR
var_logOR <- (15+7)/(15*7)#(B + C)/(B*C)
pairedOR_CI <- exp(c(log(pairedOR) - 1.96*var_logOR,log(pairedOR) - 1.96*var_logOR))
#paired OR
pairedOR <- 15/7 #B/C. also consistent with MH estimate
pairedOR
#CI based on Normal approx for logOR
var_logOR <- (15+7)/(15*7)#(B + C)/(B*C)
pairedOR_CI <- exp(c(log(pairedOR) - 1.96*var_logOR,log(pairedOR) - 1.96*var_logOR))
pairedOR_CI <- exp(c(log(pairedOR) - 1.96*var_logOR,log(pairedOR) - 1.96*var_logOR)); pairedOR_CI
pairedOR_CI <- exp(c(log(pairedOR) - 1.96*var_logOR,log(pairedOR) + 1.96*var_logOR)); pairedOR_CI
#paired OR
pairedOR <- 15/7 #B/C. also consistent with MH estimate
pairedOR
#CI based on Normal approx for logOR
var_logOR <- (15+7)/(15*7)#(B + C)/(B*C)
pairedOR_CI <- exp(c(log(pairedOR) - 1.96*var_logOR,log(pairedOR) + 1.96*var_logOR)); pairedOR_CI
q2b <- data.frame(Ton = c(26, 7), notTon = c(15, 37));q2b
#matched pair analysis
X2_MH_paired <- (15-7)^2/(15+7)#(B-C)^2/(B+C)
X2_MH_paired
X2_MH_paired
#paired OR
pairedOR <- 15/7 #B/C. also consistent with MH estimate
pairedOR
pchisq(X2_MH_paired)
pchisq(X2_MH_paired, df = 1)
qchisq(.975)
qchisq(.975, df = 1)
pchisq(X2_MH_paired, df = 1)
#matched pair analysis
X2_MH_paired <- (15-7)^2/(15+7)#(B-C)^2/(B+C)
X2_MH_paired
#matched pair analysis
X2_MH_paired <- (15-7)^2/(15+7)#(B-C)^2/(B+C)
X2_MH_paired
(15-7)^2
#matched pair analysis
X2_MH_paired <- (15-7)^2/(15+7)#(B-C)^2/(B+C)
X2_MH_paired
pchisq(X2_MH_paired, df = 1)
pchisq(7.35, df = 1)
1- pchisq(X2_MH_paired, df = 1)
1- pchisq(7.35, df = 1)
1 - pchisq(X2_MH_paired, df = 1)
1 - pchisq(X2_MH_paired, df = 1) #p-value
qgamma(p = c(0.25, 0.5, 0.75, 1), 1, 1)
setwd("/Users/cora/git_repos/RankingMethods/data")
lbw_wi <- read_csv("lbw_ct.csv")
library(tidyverse)
library(reshape2)
library(coda)
library(clue)
#small example
library(tidyverse)
library(reshape2)
library(coda)
library(clue)
setwd("/Users/cora/git_repos/RankingMethods")
lbw_ct <- read_csv("data/lbw_ct.csv")
lbw_ct
#small example
library(tidyverse)
library(reshape2)
library(coda)
library(clue)
setwd("/Users/cora/git_repos/RankingMethods")
lbw_ct <- read_csv("data/lbw_ct.csv")
lbw_ct <- lbw_ct %>% mutate(nbw=births-lbw,perc_lbw=lbw/births*100) %>% filter(!is.na(lbw))
#sample from LBW beta distribution using lbw as shape1, nbw as shape2 Q
lbw_samples <- replicate(10000,
rbeta(n = 71, shape1=lbw_ct$lbw, shape2=lbw_ct$nbw))
#if p follows beta(a,b) and y follows bin(n,p) then p|y follows beta(a+y, b+n-y)
#This is an improper prior (a,b cannot be 0), but this becomes a proper posterior
#as long as you have > 0 successes and > 0 failures. close to doing a bootstrap. like a null model.
lbw_ranks <- apply(lbw_samples,2,rank)
lbw_order <- apply(lbw_samples,2,sort)
#when you do things by rows (2), it doesn't flip. Always outputs same.
#creates 71 X 2 MATRIX of HPD intervals
lbw_HPD <- t(apply(lbw_samples,1,function(x) HPDinterval(mcmc(x))))
lbw_rank_HPD <- t(apply(lbw_ranks,1,function(x) HPDinterval(mcmc(x))))
lbw_order_HPD <- t(apply(lbw_order,1,function(x) HPDinterval(mcmc(x))))
#calculating loss on rank scale
SEL_rank <- matrix(NA,71,71) #square error loss
for (i in 1:71) {
for (j in 1:71) {
SEL_rank[i,j] <- mean((lbw_ranks[i,]-j)^2)
}
}
#calculating loss on prob scale?
SEL_prob <- matrix(NA,71,71)
for (i in 1:71) {
for (j in 1:71) {
SEL_prob[i,j] <- mean((lbw_samples[i,]-lbw_order[j,])^2)
}
}
lbw_rank_pm <- apply(lbw_ranks,1,mean) #posterior mean
lbw_rank_SEL_rank_ind_opt <- apply(SEL_rank,1,which.min) #individually optimal ranks
lbw_rank_SEL_rank_joint_opt <- as.numeric(solve_LSAP(SEL_rank)) #jointly optimal ranks
lbw_rank_SEL_prob_ind_opt <- apply(SEL_prob,1,which.min) #individually optimal ranks on pr scale
lbw_rank_SEL_prob_joint_opt <- as.numeric(solve_LSAP(SEL_prob)) #jointly optimal ranks on pr scale
#Q: to get comparison probabilities to compare. What's pr that pepin has sm rate than mil
#creates 71x71 matrix Pr(county i LBW % <county j LBW %) This is comparison-wise loss.
#a potential loss is pr of those comparisons you get right = sum(upper triangle).
#want to min(sum lower triangle). There isnt a clear algorithm that solves this.
#Diagonal should be .5 but its 0. this only matters if looking for min
prob1 <- matrix(NA,71,71)
for (i in 1:71) {
for (j in 1:71) {
prob1[i,j] <- mean(lbw_samples[i,]<lbw_samples[j,])
}
}
#prob1a <- prob1[order(rank2a),order(rank2a)]
## VISUALIZATIONS ##
#creates data frame for all the things we've calculated above for viz
lbw_results_selr <- data_frame(county=lbw_ct$county, #SEL rank scale DF
LBW_pm=apply(lbw_samples,1,mean),
LBW_LCL=lbw_HPD[,1],
LBW_UCL=lbw_HPD[,2],
LBW_rank_pm=lbw_rank_pm,
LBW_rank_io=lbw_rank_SEL_rank_ind_opt,
LBW_rank_jo=lbw_rank_SEL_rank_joint_opt,
LBW_rank_LCL=lbw_rank_HPD[,1],
LBW_rank_UCL=lbw_rank_HPD[,2]) %>%
arrange(LBW_rank_jo)
lbw_results_selp <- data_frame(county=lbw_ct$county, #pr scale DF
LBW_pm=apply(lbw_samples,1,mean),
LBW_LCL=lbw_HPD[,1],
LBW_UCL=lbw_HPD[,2],
LBW_rank_io=lbw_rank_SEL_prob_ind_opt,
LBW_rank_jo=lbw_rank_SEL_prob_joint_opt,
LBW_rank_LCL=lbw_rank_HPD[,1],
LBW_rank_UCL=lbw_rank_HPD[,2]) %>%
arrange(LBW_rank_jo)
#creates pr and scales them. Pr(given county at that rank relative to its posterior mode)
#gives realtive prob in rank direction but not relative to other counties
post_ranks <- t(apply(lbw_ranks,1,function(x) table(factor(x,levels=1:71))/max(table(factor(x,levels=1:71)))))
#post_ranks <- t(apply(lbw_ranks,1,function(x) table(factor(x,levels=1:71))/10000)) #real posterior probabilities. issue: greys out most places
#post_ranks <- post_ranks/max(post_ranks) #Q:
post_df <- melt(post_ranks) #makes it long because that's what gg plot needs
post_df$county <- lbw_ct$county[post_df$Var1]
post_df$rank <- post_df$Var2
post_df$pos <- lbw_order_stats[post_df$Var2] #TODO lbw_order_stats doesnt exist yet. needs to be created. post means of rows
post_df$county <- factor(post_df$county,levels=rev(lbw_ct$county[order(lbw_rank_SEL_prob_joint_opt)]),ordered=TRUE)
#puts them in correct order in visualization. Makes this an ordered factor. Reverse is because he wants low at top, high at bottom
#grey scale rank viz #Q
ps.options(fonts=c("serif"), width = 7, height = 7)
postscript("plots/ct_LBW_rank.eps")
ggplot(post_df,aes(x=rank,y=county,color=value))+
geom_point(pch=15,cex=2)+
scale_y_discrete("") +
scale_x_continuous("",breaks=seq(1,71,by=5)) +
#  scale_x_continuous(breaks=lbw_order_stats[c(1:7,seq(10,60,by=10),67:71)],minor_breaks=lbw_order_stats,labels=c(1:7,seq(10,60,by=10),67:71))+
scale_color_gradient(low="white",high="black",limits=c(0,1),guide=FALSE)+
theme_bw()+theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank()) +
xlab("Rank") + ggtitle("County Ranks by Rank Frequency")
dev.off()
#small example
library(tidyverse)
library(reshape2)
library(coda)
library(clue)
setwd("/Users/cora/git_repos/RankingMethods")
lbw_ct <- read_csv("data/lbw_ct.csv")
lbw_ct <- lbw_ct %>% mutate(nbw=births-lbw,perc_lbw=lbw/births*100) %>% filter(!is.na(lbw))
#sample from LBW beta distribution using lbw as shape1, nbw as shape2 Q
lbw_samples <- replicate(10000,
rbeta(n = 8, shape1=lbw_ct$lbw, shape2=lbw_ct$nbw))
#if p follows beta(a,b) and y follows bin(n,p) then p|y follows beta(a+y, b+n-y)
#This is an improper prior (a,b cannot be 0), but this becomes a proper posterior
#as long as you have > 0 successes and > 0 failures. close to doing a bootstrap. like a null model.
lbw_ranks <- apply(lbw_samples,2,rank)
lbw_order <- apply(lbw_samples,2,sort)
#when you do things by rows (2), it doesn't flip. Always outputs same.
#creates 8 X 2 MATRIX of HPD intervals
lbw_HPD <- t(apply(lbw_samples,1,function(x) HPDinterval(mcmc(x))))
lbw_rank_HPD <- t(apply(lbw_ranks,1,function(x) HPDinterval(mcmc(x))))
lbw_order_HPD <- t(apply(lbw_order,1,function(x) HPDinterval(mcmc(x))))
#calculating loss on rank scale
SEL_rank <- matrix(NA,8,8) #square error loss
for (i in 1:8) {
for (j in 1:8) {
SEL_rank[i,j] <- mean((lbw_ranks[i,]-j)^2)
}
}
#calculating loss on prob scale?
SEL_prob <- matrix(NA,8,8)
for (i in 1:8) {
for (j in 1:8) {
SEL_prob[i,j] <- mean((lbw_samples[i,]-lbw_order[j,])^2)
}
}
lbw_rank_pm <- apply(lbw_ranks,1,mean) #posterior mean
lbw_rank_SEL_rank_ind_opt <- apply(SEL_rank,1,which.min) #individually optimal ranks
lbw_rank_SEL_rank_joint_opt <- as.numeric(solve_LSAP(SEL_rank)) #jointly optimal ranks
lbw_rank_SEL_prob_ind_opt <- apply(SEL_prob,1,which.min) #individually optimal ranks on pr scale
lbw_rank_SEL_prob_joint_opt <- as.numeric(solve_LSAP(SEL_prob)) #jointly optimal ranks on pr scale
#Q: to get comparison probabilities to compare. What's pr that pepin has sm rate than mil
#creates 8x8 matrix Pr(county i LBW % <county j LBW %) This is comparison-wise loss.
#a potential loss is pr of those comparisons you get right = sum(upper triangle).
#want to min(sum lower triangle). There isnt a clear algorithm that solves this.
#Diagonal should be .5 but its 0. this only matters if looking for min
prob1 <- matrix(NA,8,8)
for (i in 1:8) {
for (j in 1:8) {
prob1[i,j] <- mean(lbw_samples[i,]<lbw_samples[j,])
}
}
#prob1a <- prob1[order(rank2a),order(rank2a)]
## VISUALIZATIONS ##
#creates data frame for all the things we've calculated above for viz
lbw_results_selr <- data_frame(county=lbw_ct$county, #SEL rank scale DF
LBW_pm=apply(lbw_samples,1,mean),
LBW_LCL=lbw_HPD[,1],
LBW_UCL=lbw_HPD[,2],
LBW_rank_pm=lbw_rank_pm,
LBW_rank_io=lbw_rank_SEL_rank_ind_opt,
LBW_rank_jo=lbw_rank_SEL_rank_joint_opt,
LBW_rank_LCL=lbw_rank_HPD[,1],
LBW_rank_UCL=lbw_rank_HPD[,2]) %>%
arrange(LBW_rank_jo)
lbw_results_selp <- data_frame(county=lbw_ct$county, #pr scale DF
LBW_pm=apply(lbw_samples,1,mean),
LBW_LCL=lbw_HPD[,1],
LBW_UCL=lbw_HPD[,2],
LBW_rank_io=lbw_rank_SEL_prob_ind_opt,
LBW_rank_jo=lbw_rank_SEL_prob_joint_opt,
LBW_rank_LCL=lbw_rank_HPD[,1],
LBW_rank_UCL=lbw_rank_HPD[,2]) %>%
arrange(LBW_rank_jo)
#creates pr and scales them. Pr(given county at that rank relative to its posterior mode)
#gives realtive prob in rank direction but not relative to other counties
post_ranks <- t(apply(lbw_ranks,1,function(x) table(factor(x,levels=1:8))/max(table(factor(x,levels=1:8)))))
#post_ranks <- t(apply(lbw_ranks,1,function(x) table(factor(x,levels=1:8))/10000)) #real posterior probabilities. issue: greys out most places
#post_ranks <- post_ranks/max(post_ranks) #Q:
post_df <- melt(post_ranks) #makes it long because that's what gg plot needs
post_df$county <- lbw_ct$county[post_df$Var1]
post_df$rank <- post_df$Var2
post_df$pos <- lbw_order_stats[post_df$Var2] #TODO lbw_order_stats doesnt exist yet. needs to be created. post means of rows
post_df$county <- factor(post_df$county,levels=rev(lbw_ct$county[order(lbw_rank_SEL_prob_joint_opt)]),ordered=TRUE)
#puts them in correct order in visualization. Makes this an ordered factor. Reverse is because he wants low at top, high at bottom
#grey scale rank viz #Q
ps.options(fonts=c("serif"), width = 7, height = 7)
postscript("plots/ct_LBW_rank.eps")
ggplot(post_df,aes(x=rank,y=county,color=value))+
geom_point(pch=15,cex=2)+
scale_y_discrete("") +
scale_x_continuous("",breaks=seq(1,8,by=5)) +
#  scale_x_continuous(breaks=lbw_order_stats[c(1:7,seq(10,60,by=10),67:8)],minor_breaks=lbw_order_stats,labels=c(1:7,seq(10,60,by=10),67:8))+
scale_color_gradient(low="white",high="black",limits=c(0,1),guide=FALSE)+
theme_bw()+theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank()) +
xlab("Rank") + ggtitle("County Ranks by Rank Frequency")
dev.off()
View(SEL_rank)
View(post_ranks)
apply(post_ranks, mean)
apply(post_ranks, Fun = mean)
apply(post_ranks, FUN = mean)
apply(post_ranks, 1FUN = mean)
apply(post_ranks, 1, FUN = mean)
apply(post_ranks, 2, FUN = mean)
#TODO lbw_order_stats doesnt exist yet. needs to be created. post means of rows
lbw_order_stats <- apply(lbw_ranks, mean)
#TODO lbw_order_stats doesnt exist yet. needs to be created. post means of rows
lbw_order_stats <- apply(lbw_ranks, 1, mean)
lbw_order_stats
lbw_order_HPD
#creates 8 X 2 MATRIX of HPD intervals
lbw_HPD <- t(apply(lbw_samples,1,function(x) HPDinterval(mcmc(x))))
lbw_order_stats <- t(apply(lbw_ranks, 1, mean))
#small example
library(tidyverse)
library(reshape2)
library(coda)
library(clue)
setwd("/Users/cora/git_repos/RankingMethods")
lbw_ct <- read_csv("data/lbw_ct.csv")
lbw_ct <- lbw_ct %>% mutate(nbw=births-lbw,perc_lbw=lbw/births*100) %>% filter(!is.na(lbw))
#sample from LBW beta distribution using lbw as shape1, nbw as shape2 Q
lbw_samples <- replicate(10000,
rbeta(n = 8, shape1=lbw_ct$lbw, shape2=lbw_ct$nbw))
#if p follows beta(a,b) and y follows bin(n,p) then p|y follows beta(a+y, b+n-y)
#This is an improper prior (a,b cannot be 0), but this becomes a proper posterior
#as long as you have > 0 successes and > 0 failures. close to doing a bootstrap. like a null model.
lbw_ranks <- apply(lbw_samples,2,rank)
lbw_order <- apply(lbw_samples,2,sort)
#when you do things by rows (2), it doesn't flip. Always outputs same.
#creates 8 X 2 MATRIX of HPD intervals
lbw_HPD <- t(apply(lbw_samples,1,function(x) HPDinterval(mcmc(x))))
lbw_order_stats <- t(apply(lbw_ranks, 1, mean))
lbw_rank_HPD <- t(apply(lbw_ranks,1,function(x) HPDinterval(mcmc(x))))
lbw_order_HPD <- t(apply(lbw_order,1,function(x) HPDinterval(mcmc(x))))
#calculating loss on rank scale
SEL_rank <- matrix(NA,8,8) #square error loss
for (i in 1:8) {
for (j in 1:8) {
SEL_rank[i,j] <- mean((lbw_ranks[i,]-j)^2)
}
}
#calculating loss on prob scale?
SEL_prob <- matrix(NA,8,8)
for (i in 1:8) {
for (j in 1:8) {
SEL_prob[i,j] <- mean((lbw_samples[i,]-lbw_order[j,])^2)
}
}
lbw_rank_pm <- apply(lbw_ranks,1,mean) #posterior mean
lbw_rank_SEL_rank_ind_opt <- apply(SEL_rank,1,which.min) #individually optimal ranks
lbw_rank_SEL_rank_joint_opt <- as.numeric(solve_LSAP(SEL_rank)) #jointly optimal ranks
lbw_rank_SEL_prob_ind_opt <- apply(SEL_prob,1,which.min) #individually optimal ranks on pr scale
lbw_rank_SEL_prob_joint_opt <- as.numeric(solve_LSAP(SEL_prob)) #jointly optimal ranks on pr scale
#Q: to get comparison probabilities to compare. What's pr that pepin has sm rate than mil
#creates 8x8 matrix Pr(county i LBW % <county j LBW %) This is comparison-wise loss.
#a potential loss is pr of those comparisons you get right = sum(upper triangle).
#want to min(sum lower triangle). There isnt a clear algorithm that solves this.
#Diagonal should be .5 but its 0. this only matters if looking for min
prob1 <- matrix(NA,8,8)
for (i in 1:8) {
for (j in 1:8) {
prob1[i,j] <- mean(lbw_samples[i,]<lbw_samples[j,])
}
}
#prob1a <- prob1[order(rank2a),order(rank2a)]
## VISUALIZATIONS ##
#creates data frame for all the things we've calculated above for viz
lbw_results_selr <- data_frame(county=lbw_ct$county, #SEL rank scale DF
LBW_pm=apply(lbw_samples,1,mean),
LBW_LCL=lbw_HPD[,1],
LBW_UCL=lbw_HPD[,2],
LBW_rank_pm=lbw_rank_pm,
LBW_rank_io=lbw_rank_SEL_rank_ind_opt,
LBW_rank_jo=lbw_rank_SEL_rank_joint_opt,
LBW_rank_LCL=lbw_rank_HPD[,1],
LBW_rank_UCL=lbw_rank_HPD[,2]) %>%
arrange(LBW_rank_jo)
lbw_results_selp <- data_frame(county=lbw_ct$county, #pr scale DF
LBW_pm=apply(lbw_samples,1,mean),
LBW_LCL=lbw_HPD[,1],
LBW_UCL=lbw_HPD[,2],
LBW_rank_io=lbw_rank_SEL_prob_ind_opt,
LBW_rank_jo=lbw_rank_SEL_prob_joint_opt,
LBW_rank_LCL=lbw_rank_HPD[,1],
LBW_rank_UCL=lbw_rank_HPD[,2]) %>%
arrange(LBW_rank_jo)
#creates pr and scales them. Pr(given county at that rank relative to its posterior mode)
#gives realtive prob in rank direction but not relative to other counties
post_ranks <- t(apply(lbw_ranks,1,function(x) table(factor(x,levels=1:8))/max(table(factor(x,levels=1:8)))))
#post_ranks <- t(apply(lbw_ranks,1,function(x) table(factor(x,levels=1:8))/10000)) #real posterior probabilities. issue: greys out most places
#post_ranks <- post_ranks/max(post_ranks) #Q:
post_df <- melt(post_ranks) #makes it long because that's what gg plot needs
post_df$county <- lbw_ct$county[post_df$Var1]
post_df$rank <- post_df$Var2
post_df$pos <- lbw_order_stats[post_df$Var2]
post_df$county <- factor(post_df$county,levels=rev(lbw_ct$county[order(lbw_rank_SEL_prob_joint_opt)]),ordered=TRUE)
#puts them in correct order in visualization. Makes this an ordered factor. Reverse is because he wants low at top, high at bottom
#grey scale rank viz #Q
ps.options(fonts=c("serif"), width = 7, height = 7)
postscript("plots/ct_LBW_rank.eps")
ggplot(post_df,aes(x=rank,y=county,color=value))+
geom_point(pch=15,cex=2)+
scale_y_discrete("") +
scale_x_continuous("",breaks=seq(1,8,by=5)) +
#  scale_x_continuous(breaks=lbw_order_stats[c(1:7,seq(10,60,by=10),67:8)],minor_breaks=lbw_order_stats,labels=c(1:7,seq(10,60,by=10),67:8))+
scale_color_gradient(low="white",high="black",limits=c(0,1),guide=FALSE)+
theme_bw()+theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank()) +
xlab("Rank") + ggtitle("County Ranks by Rank Frequency")
dev.off()
#grey scale rank viz #Q
ps.options(fonts=c("serif"), width = 7, height = 7)
postscript("plots/ct_LBW_rank.eps")
ggplot(post_df,aes(x=rank,y=county,color=value))+
geom_point(pch=15,cex=4)+
scale_y_discrete("") +
scale_x_continuous("",breaks=seq(1,8,by=5)) +
#  scale_x_continuous(breaks=lbw_order_stats[c(1:7,seq(10,60,by=10),67:8)],minor_breaks=lbw_order_stats,labels=c(1:7,seq(10,60,by=10),67:8))+
scale_color_gradient(low="white",high="black",limits=c(0,1),guide=FALSE)+
theme_bw()+theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank()) +
xlab("Rank") + ggtitle("County Ranks by Rank Frequency")
dev.off()
#grey scale rank viz #Q
ps.options(fonts=c("serif"), width = 7, height = 7)
postscript("plots/ct_LBW_rank.eps")
ggplot(post_df,aes(x=rank,y=county,color=value))+
geom_point(pch=15,cex=10)+
scale_y_discrete("") +
scale_x_continuous("",breaks=seq(1,8,by=5)) +
#  scale_x_continuous(breaks=lbw_order_stats[c(1:7,seq(10,60,by=10),67:8)],minor_breaks=lbw_order_stats,labels=c(1:7,seq(10,60,by=10),67:8))+
scale_color_gradient(low="white",high="black",limits=c(0,1),guide=FALSE)+
theme_bw()+theme(panel.grid.major=element_blank(),panel.grid.minor=element_blank()) +
xlab("Rank") + ggtitle("County Ranks by Rank Frequency")
dev.off()
View(post_df)
library(xtable)
View(post_df)
View(post_df)
##TABLES
xtable(lbw_ct)
##TABLES
xtable(lbw_ct[1:4])
